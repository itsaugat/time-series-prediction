{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/EURGBP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.6472</td>\n",
       "      <td>0.6472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-06</td>\n",
       "      <td>0.6471</td>\n",
       "      <td>0.6523</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>0.6498</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close  Adj Close  Volume\n",
       "0  2003-01-01  0.6547  0.6547  0.6497  0.6504     0.6504     0.0\n",
       "1  2003-01-02  0.6503  0.6627  0.6475  0.6494     0.6494     0.0\n",
       "2  2003-01-03  0.6496  0.6516  0.6466  0.6472     0.6472     0.0\n",
       "3  2003-01-06  0.6471  0.6523  0.6467  0.6502     0.6502     0.0\n",
       "4  2003-01-07  0.6498  0.6510  0.6477  0.6490     0.6490     0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.86070</td>\n",
       "      <td>0.84913</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>0.85520</td>\n",
       "      <td>0.85550</td>\n",
       "      <td>0.85290</td>\n",
       "      <td>0.85530</td>\n",
       "      <td>0.85530</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>0.85370</td>\n",
       "      <td>0.85632</td>\n",
       "      <td>0.85095</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>0.85406</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.85128</td>\n",
       "      <td>0.85406</td>\n",
       "      <td>0.85406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.85419</td>\n",
       "      <td>0.85480</td>\n",
       "      <td>0.84544</td>\n",
       "      <td>0.85426</td>\n",
       "      <td>0.85426</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     Open     High      Low    Close  Adj Close  Volume\n",
       "4430  2019-12-25  0.85700  0.86070  0.84913  0.85700    0.85700     0.0\n",
       "4431  2019-12-26  0.85520  0.85550  0.85290  0.85530    0.85530     0.0\n",
       "4432  2019-12-27  0.85370  0.85632  0.85095  0.85380    0.85380     0.0\n",
       "4433  2019-12-30  0.85406  0.85558  0.85128  0.85406    0.85406     0.0\n",
       "4434  2019-12-31  0.85419  0.85480  0.84544  0.85426    0.85426     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.1\n",
    "split = len(data) - round(test_frac*len(data))\n",
    "#split\n",
    "df_train = data[:split]\n",
    "df_test = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3965\n",
      "441\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#sc = MinMaxScaler()\n",
    "sc = StandardScaler()\n",
    "df_train_scale = sc.fit_transform(df_train['Close'].values.reshape(-1,1))\n",
    "df_test_scale = sc.transform(df_test['Close'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.61547514],\n",
       "       [-1.6276607 ],\n",
       "       [-1.65446891],\n",
       "       ...,\n",
       "       [ 1.09641972],\n",
       "       [ 1.09958796],\n",
       "       [ 1.09934425]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_time_step = 16\n",
    "output_time_step = [2,3,5,7,10]\n",
    "epoch = 1000\n",
    "batch_size = 32\n",
    "validation_split=0.1\n",
    "optimizer = 'adam'\n",
    "loss = 'mean_squared_error'\n",
    "dropout = 0.1\n",
    "lstm_units = 100\n",
    "callback = EarlyStopping(monitor = 'val_loss', \n",
    "                         min_delta = 1e-4, \n",
    "                         patience = 100, \n",
    "                         verbose=1, \n",
    "                         mode='auto', \n",
    "                         restore_best_weights=True)\n",
    "RMSE = []\n",
    "MAE = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3947, 16, 1)\n",
      "(3947, 2)\n",
      "Train on 3552 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3552/3552 [==============================] - 1s 353us/step - loss: 0.0934 - val_loss: 0.0432\n",
      "Epoch 2/1000\n",
      "3552/3552 [==============================] - 1s 239us/step - loss: 0.0231 - val_loss: 0.0183\n",
      "Epoch 3/1000\n",
      "3552/3552 [==============================] - 1s 237us/step - loss: 0.0196 - val_loss: 0.0120\n",
      "Epoch 4/1000\n",
      "3552/3552 [==============================] - 1s 236us/step - loss: 0.0170 - val_loss: 0.0161\n",
      "Epoch 5/1000\n",
      "3552/3552 [==============================] - 1s 233us/step - loss: 0.0153 - val_loss: 0.0187\n",
      "Epoch 6/1000\n",
      "3552/3552 [==============================] - 1s 245us/step - loss: 0.0143 - val_loss: 0.0179\n",
      "Epoch 7/1000\n",
      "3552/3552 [==============================] - 1s 250us/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 8/1000\n",
      "3552/3552 [==============================] - 1s 236us/step - loss: 0.0131 - val_loss: 0.0113\n",
      "Epoch 9/1000\n",
      "3552/3552 [==============================] - 1s 230us/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 10/1000\n",
      "3552/3552 [==============================] - 1s 231us/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 11/1000\n",
      "3552/3552 [==============================] - 1s 231us/step - loss: 0.0111 - val_loss: 0.0083\n",
      "Epoch 12/1000\n",
      "3552/3552 [==============================] - 1s 347us/step - loss: 0.0097 - val_loss: 0.0072\n",
      "Epoch 13/1000\n",
      "3552/3552 [==============================] - 1s 387us/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 14/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0091 - val_loss: 0.0072\n",
      "Epoch 15/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0091 - val_loss: 0.0083\n",
      "Epoch 16/1000\n",
      "3552/3552 [==============================] - 1s 386us/step - loss: 0.0089 - val_loss: 0.0082\n",
      "Epoch 17/1000\n",
      "3552/3552 [==============================] - 1s 385us/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 18/1000\n",
      "3552/3552 [==============================] - 1s 385us/step - loss: 0.0086 - val_loss: 0.0075\n",
      "Epoch 19/1000\n",
      "3552/3552 [==============================] - 1s 385us/step - loss: 0.0082 - val_loss: 0.0069\n",
      "Epoch 20/1000\n",
      "3552/3552 [==============================] - 1s 385us/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 21/1000\n",
      "3552/3552 [==============================] - 1s 385us/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 22/1000\n",
      "3552/3552 [==============================] - 1s 385us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 23/1000\n",
      "3552/3552 [==============================] - 1s 383us/step - loss: 0.0077 - val_loss: 0.0070\n",
      "Epoch 24/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0076 - val_loss: 0.0056\n",
      "Epoch 25/1000\n",
      "3552/3552 [==============================] - 1s 393us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 26/1000\n",
      "3552/3552 [==============================] - 1s 230us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 27/1000\n",
      "3552/3552 [==============================] - 1s 335us/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 28/1000\n",
      "3552/3552 [==============================] - 1s 379us/step - loss: 0.0074 - val_loss: 0.0070\n",
      "Epoch 29/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 30/1000\n",
      "3552/3552 [==============================] - 1s 386us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 31/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 32/1000\n",
      "3552/3552 [==============================] - 1s 345us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 33/1000\n",
      "3552/3552 [==============================] - 1s 372us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 34/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 35/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 36/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 37/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 38/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 39/1000\n",
      "3552/3552 [==============================] - 1s 364us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 40/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 41/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 42/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 43/1000\n",
      "3552/3552 [==============================] - 1s 364us/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 44/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 45/1000\n",
      "3552/3552 [==============================] - 1s 367us/step - loss: 0.0061 - val_loss: 0.0048\n",
      "Epoch 46/1000\n",
      "3552/3552 [==============================] - 1s 367us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 47/1000\n",
      "3552/3552 [==============================] - 1s 366us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 48/1000\n",
      "3552/3552 [==============================] - 1s 374us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 49/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 50/1000\n",
      "3552/3552 [==============================] - 1s 364us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 51/1000\n",
      "3552/3552 [==============================] - 1s 367us/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 52/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 53/1000\n",
      "3552/3552 [==============================] - 1s 368us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 54/1000\n",
      "3552/3552 [==============================] - 1s 368us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 55/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 56/1000\n",
      "3552/3552 [==============================] - 1s 366us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 57/1000\n",
      "3552/3552 [==============================] - 1s 364us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 58/1000\n",
      "3552/3552 [==============================] - 1s 365us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 59/1000\n",
      "3552/3552 [==============================] - 1s 367us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 60/1000\n",
      "3552/3552 [==============================] - 1s 366us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 61/1000\n",
      "3552/3552 [==============================] - 1s 364us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 62/1000\n",
      "3552/3552 [==============================] - 1s 368us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 63/1000\n",
      "3552/3552 [==============================] - 1s 382us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 64/1000\n",
      "3552/3552 [==============================] - 1s 407us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 65/1000\n",
      "3552/3552 [==============================] - 1s 367us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 66/1000\n",
      "3552/3552 [==============================] - 1s 367us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 67/1000\n",
      "3552/3552 [==============================] - 1s 366us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 68/1000\n",
      "3552/3552 [==============================] - 1s 367us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 69/1000\n",
      "3552/3552 [==============================] - 1s 366us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 70/1000\n",
      "3552/3552 [==============================] - 1s 366us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 71/1000\n",
      "3552/3552 [==============================] - 1s 366us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 72/1000\n",
      "3552/3552 [==============================] - 1s 371us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 73/1000\n",
      "3552/3552 [==============================] - 1s 348us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 74/1000\n",
      "3552/3552 [==============================] - 1s 338us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 75/1000\n",
      "3552/3552 [==============================] - 1s 371us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 76/1000\n",
      "3552/3552 [==============================] - 1s 415us/step - loss: 0.0058 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/1000\n",
      "3552/3552 [==============================] - 2s 453us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 78/1000\n",
      "3552/3552 [==============================] - 2s 445us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 79/1000\n",
      "3552/3552 [==============================] - 2s 423us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 80/1000\n",
      "3552/3552 [==============================] - 2s 437us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 81/1000\n",
      "3552/3552 [==============================] - 1s 390us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 82/1000\n",
      "3552/3552 [==============================] - 2s 498us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 83/1000\n",
      "3552/3552 [==============================] - 2s 439us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 84/1000\n",
      "3552/3552 [==============================] - 2s 468us/step - loss: 0.0056 - val_loss: 0.0046\n",
      "Epoch 85/1000\n",
      "3552/3552 [==============================] - 2s 446us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 86/1000\n",
      "3552/3552 [==============================] - 1s 375us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 87/1000\n",
      "3552/3552 [==============================] - 1s 388us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 88/1000\n",
      "3552/3552 [==============================] - 1s 408us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 89/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 90/1000\n",
      "3552/3552 [==============================] - 1s 383us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 91/1000\n",
      "3552/3552 [==============================] - 1s 409us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 92/1000\n",
      "3552/3552 [==============================] - 1s 380us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 93/1000\n",
      "3552/3552 [==============================] - 1s 379us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 94/1000\n",
      "3552/3552 [==============================] - 1s 379us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 95/1000\n",
      "3552/3552 [==============================] - 1s 380us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 96/1000\n",
      "3552/3552 [==============================] - 1s 416us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 97/1000\n",
      "3552/3552 [==============================] - 1s 400us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 98/1000\n",
      "3552/3552 [==============================] - 1s 382us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 99/1000\n",
      "3552/3552 [==============================] - 1s 248us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 100/1000\n",
      "3552/3552 [==============================] - 1s 354us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 101/1000\n",
      "3552/3552 [==============================] - 1s 395us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 102/1000\n",
      "3552/3552 [==============================] - 1s 417us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 103/1000\n",
      "3552/3552 [==============================] - 1s 420us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 104/1000\n",
      "3552/3552 [==============================] - 1s 422us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 105/1000\n",
      "3552/3552 [==============================] - 2s 436us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 106/1000\n",
      "3552/3552 [==============================] - 2s 459us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 107/1000\n",
      "3552/3552 [==============================] - 1s 412us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 108/1000\n",
      "3552/3552 [==============================] - 1s 410us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 109/1000\n",
      "3552/3552 [==============================] - 1s 406us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 110/1000\n",
      "3552/3552 [==============================] - 1s 408us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 111/1000\n",
      "3552/3552 [==============================] - 1s 407us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 112/1000\n",
      "3552/3552 [==============================] - 1s 409us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 113/1000\n",
      "3552/3552 [==============================] - 2s 430us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 114/1000\n",
      "3552/3552 [==============================] - 2s 449us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 115/1000\n",
      "3552/3552 [==============================] - 1s 414us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 116/1000\n",
      "3552/3552 [==============================] - 1s 291us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 117/1000\n",
      "3552/3552 [==============================] - 1s 266us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 118/1000\n",
      "3552/3552 [==============================] - 1s 356us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 119/1000\n",
      "3552/3552 [==============================] - 1s 388us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 120/1000\n",
      "3552/3552 [==============================] - 1s 387us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 121/1000\n",
      "3552/3552 [==============================] - 1s 389us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 122/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 123/1000\n",
      "3552/3552 [==============================] - 1s 386us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 124/1000\n",
      "3552/3552 [==============================] - 1s 384us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 125/1000\n",
      "3552/3552 [==============================] - 1s 387us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 126/1000\n",
      "3552/3552 [==============================] - 1s 386us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 127/1000\n",
      "3552/3552 [==============================] - 1s 386us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 128/1000\n",
      "3552/3552 [==============================] - 1s 374us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 129/1000\n",
      "3552/3552 [==============================] - 1s 314us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 130/1000\n",
      "3552/3552 [==============================] - 2s 429us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 131/1000\n",
      "3552/3552 [==============================] - 2s 439us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 132/1000\n",
      "3552/3552 [==============================] - 1s 422us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 133/1000\n",
      "3552/3552 [==============================] - 2s 429us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 134/1000\n",
      "3552/3552 [==============================] - 2s 425us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 135/1000\n",
      "3552/3552 [==============================] - 2s 427us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 136/1000\n",
      "3552/3552 [==============================] - 1s 422us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 137/1000\n",
      "3552/3552 [==============================] - 1s 422us/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 138/1000\n",
      "3552/3552 [==============================] - 1s 357us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 139/1000\n",
      "3552/3552 [==============================] - 1s 314us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 140/1000\n",
      "3552/3552 [==============================] - 1s 393us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 141/1000\n",
      "3552/3552 [==============================] - 1s 410us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 142/1000\n",
      "3552/3552 [==============================] - 2s 423us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 143/1000\n",
      "3552/3552 [==============================] - 1s 398us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 144/1000\n",
      "3552/3552 [==============================] - 1s 400us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 145/1000\n",
      "3552/3552 [==============================] - 2s 432us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 146/1000\n",
      "3552/3552 [==============================] - 2s 428us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 147/1000\n",
      "3552/3552 [==============================] - 1s 421us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 148/1000\n",
      "3552/3552 [==============================] - 2s 431us/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 149/1000\n",
      "3552/3552 [==============================] - 1s 359us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 150/1000\n",
      "3552/3552 [==============================] - 1s 412us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 151/1000\n",
      "3552/3552 [==============================] - 1s 420us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 152/1000\n",
      "3552/3552 [==============================] - 2s 429us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552/3552 [==============================] - 2s 438us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 154/1000\n",
      "3552/3552 [==============================] - 2s 428us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 155/1000\n",
      "3552/3552 [==============================] - 1s 413us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 156/1000\n",
      "3552/3552 [==============================] - 1s 406us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 157/1000\n",
      "3552/3552 [==============================] - 1s 422us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 158/1000\n",
      "3552/3552 [==============================] - 1s 409us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00158: early stopping\n",
      "(423, 2)\n",
      "(423, 2)\n",
      "(3946, 16, 1)\n",
      "(3946, 3)\n",
      "Train on 3551 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3551/3551 [==============================] - 2s 490us/step - loss: 0.1062 - val_loss: 0.0245\n",
      "Epoch 2/1000\n",
      "3551/3551 [==============================] - 1s 402us/step - loss: 0.0250 - val_loss: 0.0146\n",
      "Epoch 3/1000\n",
      "3551/3551 [==============================] - 1s 410us/step - loss: 0.0209 - val_loss: 0.0193\n",
      "Epoch 4/1000\n",
      "3551/3551 [==============================] - 1s 410us/step - loss: 0.0197 - val_loss: 0.0223\n",
      "Epoch 5/1000\n",
      "3551/3551 [==============================] - 2s 429us/step - loss: 0.0186 - val_loss: 0.0183\n",
      "Epoch 6/1000\n",
      "3551/3551 [==============================] - 1s 409us/step - loss: 0.0164 - val_loss: 0.0148\n",
      "Epoch 7/1000\n",
      "3551/3551 [==============================] - 1s 409us/step - loss: 0.0152 - val_loss: 0.0153\n",
      "Epoch 8/1000\n",
      "3551/3551 [==============================] - 1s 408us/step - loss: 0.0146 - val_loss: 0.0165\n",
      "Epoch 9/1000\n",
      "3551/3551 [==============================] - 1s 410us/step - loss: 0.0141 - val_loss: 0.0109\n",
      "Epoch 10/1000\n",
      "3551/3551 [==============================] - 1s 394us/step - loss: 0.0129 - val_loss: 0.0096\n",
      "Epoch 11/1000\n",
      "3551/3551 [==============================] - 1s 331us/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 12/1000\n",
      "3551/3551 [==============================] - 2s 448us/step - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 13/1000\n",
      "3551/3551 [==============================] - 2s 423us/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 14/1000\n",
      "3551/3551 [==============================] - 2s 430us/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 15/1000\n",
      "3551/3551 [==============================] - 2s 439us/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 16/1000\n",
      "3551/3551 [==============================] - 1s 421us/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 17/1000\n",
      "3551/3551 [==============================] - 2s 440us/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 18/1000\n",
      "3551/3551 [==============================] - 1s 409us/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 19/1000\n",
      "3551/3551 [==============================] - 1s 408us/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 20/1000\n",
      "3551/3551 [==============================] - 1s 413us/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 21/1000\n",
      "3551/3551 [==============================] - 2s 451us/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 22/1000\n",
      "3551/3551 [==============================] - 1s 354us/step - loss: 0.0094 - val_loss: 0.0075\n",
      "Epoch 23/1000\n",
      "3551/3551 [==============================] - 1s 350us/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 24/1000\n",
      "3551/3551 [==============================] - 1s 336us/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 25/1000\n",
      "3551/3551 [==============================] - 1s 335us/step - loss: 0.0091 - val_loss: 0.0071\n",
      "Epoch 26/1000\n",
      "3551/3551 [==============================] - 1s 335us/step - loss: 0.0090 - val_loss: 0.0068\n",
      "Epoch 27/1000\n",
      "3551/3551 [==============================] - 1s 354us/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 28/1000\n",
      "3551/3551 [==============================] - 1s 349us/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 29/1000\n",
      "3551/3551 [==============================] - 1s 336us/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 30/1000\n",
      "3551/3551 [==============================] - 1s 359us/step - loss: 0.0087 - val_loss: 0.0082\n",
      "Epoch 31/1000\n",
      "3551/3551 [==============================] - 1s 382us/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 32/1000\n",
      "3551/3551 [==============================] - 1s 388us/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 33/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 34/1000\n",
      "3551/3551 [==============================] - 1s 401us/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 35/1000\n",
      "3551/3551 [==============================] - 1s 405us/step - loss: 0.0082 - val_loss: 0.0064\n",
      "Epoch 36/1000\n",
      "3551/3551 [==============================] - 1s 402us/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 37/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0080 - val_loss: 0.0063\n",
      "Epoch 38/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 39/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0082 - val_loss: 0.0073\n",
      "Epoch 40/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 41/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0081 - val_loss: 0.0075\n",
      "Epoch 42/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0082 - val_loss: 0.0075\n",
      "Epoch 43/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0079 - val_loss: 0.0077\n",
      "Epoch 44/1000\n",
      "3551/3551 [==============================] - 1s 388us/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 45/1000\n",
      "3551/3551 [==============================] - 1s 412us/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 46/1000\n",
      "3551/3551 [==============================] - 1s 311us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 47/1000\n",
      "3551/3551 [==============================] - 1s 314us/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 48/1000\n",
      "3551/3551 [==============================] - 1s 392us/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 49/1000\n",
      "3551/3551 [==============================] - 1s 397us/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 50/1000\n",
      "3551/3551 [==============================] - 1s 388us/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 51/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 52/1000\n",
      "3551/3551 [==============================] - 1s 388us/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 53/1000\n",
      "3551/3551 [==============================] - 1s 419us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 54/1000\n",
      "3551/3551 [==============================] - 1s 398us/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 55/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 56/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 57/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 58/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 59/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 60/1000\n",
      "3551/3551 [==============================] - 1s 381us/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 61/1000\n",
      "3551/3551 [==============================] - 1s 276us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 62/1000\n",
      "3551/3551 [==============================] - 1s 380us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 63/1000\n",
      "3551/3551 [==============================] - 1s 401us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 64/1000\n",
      "3551/3551 [==============================] - 1s 401us/step - loss: 0.0074 - val_loss: 0.0061\n",
      "Epoch 65/1000\n",
      "3551/3551 [==============================] - 2s 424us/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 66/1000\n",
      "3551/3551 [==============================] - 2s 431us/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 67/1000\n",
      "3551/3551 [==============================] - 1s 412us/step - loss: 0.0077 - val_loss: 0.0062\n",
      "Epoch 68/1000\n",
      "3551/3551 [==============================] - 1s 416us/step - loss: 0.0077 - val_loss: 0.0059\n",
      "Epoch 69/1000\n",
      "3551/3551 [==============================] - 1s 410us/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551/3551 [==============================] - 1s 402us/step - loss: 0.0075 - val_loss: 0.0060\n",
      "Epoch 71/1000\n",
      "3551/3551 [==============================] - 1s 402us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 72/1000\n",
      "3551/3551 [==============================] - 1s 407us/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 73/1000\n",
      "3551/3551 [==============================] - 1s 404us/step - loss: 0.0073 - val_loss: 0.0062\n",
      "Epoch 74/1000\n",
      "3551/3551 [==============================] - 2s 429us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 75/1000\n",
      "3551/3551 [==============================] - 2s 447us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 76/1000\n",
      "3551/3551 [==============================] - 2s 428us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 77/1000\n",
      "3551/3551 [==============================] - 1s 407us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 78/1000\n",
      "3551/3551 [==============================] - 1s 420us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 79/1000\n",
      "3551/3551 [==============================] - 1s 412us/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 80/1000\n",
      "3551/3551 [==============================] - 1s 411us/step - loss: 0.0072 - val_loss: 0.0063\n",
      "Epoch 81/1000\n",
      "3551/3551 [==============================] - 1s 415us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 82/1000\n",
      "3551/3551 [==============================] - 2s 429us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 83/1000\n",
      "3551/3551 [==============================] - 2s 441us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 84/1000\n",
      "3551/3551 [==============================] - 2s 423us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 85/1000\n",
      "3551/3551 [==============================] - 1s 259us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 86/1000\n",
      "3551/3551 [==============================] - 1s 219us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 87/1000\n",
      "3551/3551 [==============================] - 1s 324us/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 88/1000\n",
      "3551/3551 [==============================] - 1s 388us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 89/1000\n",
      "3551/3551 [==============================] - 1s 406us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 90/1000\n",
      "3551/3551 [==============================] - 1s 389us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 91/1000\n",
      "3551/3551 [==============================] - 1s 392us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 92/1000\n",
      "3551/3551 [==============================] - 1s 389us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 93/1000\n",
      "3551/3551 [==============================] - 1s 388us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 94/1000\n",
      "3551/3551 [==============================] - 1s 385us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 95/1000\n",
      "3551/3551 [==============================] - 1s 384us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 96/1000\n",
      "3551/3551 [==============================] - 1s 385us/step - loss: 0.0071 - val_loss: 0.0057\n",
      "Epoch 97/1000\n",
      "3551/3551 [==============================] - 1s 387us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 98/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 99/1000\n",
      "3551/3551 [==============================] - 1s 390us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 100/1000\n",
      "3551/3551 [==============================] - 1s 389us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 101/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 102/1000\n",
      "3551/3551 [==============================] - 1s 385us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 103/1000\n",
      "3551/3551 [==============================] - 1s 386us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 104/1000\n",
      "3551/3551 [==============================] - 1s 413us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 105/1000\n",
      "3551/3551 [==============================] - 1s 299us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 106/1000\n",
      "3551/3551 [==============================] - 1s 267us/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 107/1000\n",
      "3551/3551 [==============================] - 1s 324us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 108/1000\n",
      "3551/3551 [==============================] - 2s 448us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 109/1000\n",
      "3551/3551 [==============================] - 2s 440us/step - loss: 0.0073 - val_loss: 0.0058\n",
      "Epoch 110/1000\n",
      "3551/3551 [==============================] - 1s 409us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 111/1000\n",
      "3551/3551 [==============================] - 1s 411us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 112/1000\n",
      "3551/3551 [==============================] - 1s 411us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 113/1000\n",
      "3551/3551 [==============================] - 1s 407us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 114/1000\n",
      "3551/3551 [==============================] - 2s 425us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 115/1000\n",
      "3551/3551 [==============================] - 2s 435us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 116/1000\n",
      "3551/3551 [==============================] - 2s 434us/step - loss: 0.0079 - val_loss: 0.0058\n",
      "Epoch 117/1000\n",
      "3551/3551 [==============================] - 2s 423us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 118/1000\n",
      "3551/3551 [==============================] - 2s 435us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 119/1000\n",
      "3551/3551 [==============================] - 2s 434us/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 120/1000\n",
      "3551/3551 [==============================] - 1s 272us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 121/1000\n",
      "3551/3551 [==============================] - 1s 307us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 122/1000\n",
      "3551/3551 [==============================] - 1s 419us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 123/1000\n",
      "3551/3551 [==============================] - 2s 461us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 124/1000\n",
      "3551/3551 [==============================] - 1s 419us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 125/1000\n",
      "3551/3551 [==============================] - 1s 410us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 126/1000\n",
      "3551/3551 [==============================] - 1s 409us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 127/1000\n",
      "3551/3551 [==============================] - 1s 412us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 128/1000\n",
      "3551/3551 [==============================] - 2s 434us/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 129/1000\n",
      "3551/3551 [==============================] - 1s 412us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 130/1000\n",
      "3551/3551 [==============================] - 1s 410us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 131/1000\n",
      "3551/3551 [==============================] - 1s 411us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 132/1000\n",
      "3551/3551 [==============================] - 1s 411us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 133/1000\n",
      "3551/3551 [==============================] - 2s 449us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 134/1000\n",
      "3551/3551 [==============================] - 2s 425us/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 135/1000\n",
      "3551/3551 [==============================] - 2s 434us/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 136/1000\n",
      "3551/3551 [==============================] - 2s 435us/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 137/1000\n",
      "3551/3551 [==============================] - 1s 371us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 138/1000\n",
      "3551/3551 [==============================] - 1s 343us/step - loss: 0.0073 - val_loss: 0.0059\n",
      "Epoch 139/1000\n",
      "3551/3551 [==============================] - 1s 342us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 140/1000\n",
      "3551/3551 [==============================] - 1s 334us/step - loss: 0.0072 - val_loss: 0.0059\n",
      "Epoch 141/1000\n",
      "3551/3551 [==============================] - 1s 334us/step - loss: 0.0070 - val_loss: 0.0059\n",
      "Epoch 142/1000\n",
      "3551/3551 [==============================] - 1s 336us/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 143/1000\n",
      "3551/3551 [==============================] - 1s 336us/step - loss: 0.0071 - val_loss: 0.0058\n",
      "Epoch 144/1000\n",
      "3551/3551 [==============================] - 1s 355us/step - loss: 0.0072 - val_loss: 0.0060\n",
      "Epoch 145/1000\n",
      "3551/3551 [==============================] - 1s 334us/step - loss: 0.0072 - val_loss: 0.0065\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551/3551 [==============================] - 1s 336us/step - loss: 0.0071 - val_loss: 0.0062\n",
      "Epoch 147/1000\n",
      "3551/3551 [==============================] - 1s 351us/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 148/1000\n",
      "3551/3551 [==============================] - 1s 342us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 149/1000\n",
      "3551/3551 [==============================] - 1s 374us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 150/1000\n",
      "3551/3551 [==============================] - 1s 389us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 151/1000\n",
      "3551/3551 [==============================] - 1s 388us/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00151: early stopping\n",
      "(422, 3)\n",
      "(422, 3)\n",
      "(3944, 16, 1)\n",
      "(3944, 5)\n",
      "Train on 3549 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3549/3549 [==============================] - 2s 480us/step - loss: 0.1291 - val_loss: 0.0530\n",
      "Epoch 2/1000\n",
      "3549/3549 [==============================] - 1s 416us/step - loss: 0.0340 - val_loss: 0.0264\n",
      "Epoch 3/1000\n",
      "3549/3549 [==============================] - 1s 399us/step - loss: 0.0284 - val_loss: 0.0202\n",
      "Epoch 4/1000\n",
      "3549/3549 [==============================] - 1s 387us/step - loss: 0.0259 - val_loss: 0.0241\n",
      "Epoch 5/1000\n",
      "3549/3549 [==============================] - 1s 404us/step - loss: 0.0248 - val_loss: 0.0242\n",
      "Epoch 6/1000\n",
      "3549/3549 [==============================] - 1s 422us/step - loss: 0.0213 - val_loss: 0.0205\n",
      "Epoch 7/1000\n",
      "3549/3549 [==============================] - 1s 411us/step - loss: 0.0202 - val_loss: 0.0191\n",
      "Epoch 8/1000\n",
      "3549/3549 [==============================] - 1s 409us/step - loss: 0.0195 - val_loss: 0.0186\n",
      "Epoch 9/1000\n",
      "3549/3549 [==============================] - 1s 373us/step - loss: 0.0184 - val_loss: 0.0158\n",
      "Epoch 10/1000\n",
      "3549/3549 [==============================] - 1s 408us/step - loss: 0.0174 - val_loss: 0.0151\n",
      "Epoch 11/1000\n",
      "3549/3549 [==============================] - 1s 404us/step - loss: 0.0172 - val_loss: 0.0132\n",
      "Epoch 12/1000\n",
      "3549/3549 [==============================] - 1s 403us/step - loss: 0.0162 - val_loss: 0.0154\n",
      "Epoch 13/1000\n",
      "3549/3549 [==============================] - 1s 409us/step - loss: 0.0159 - val_loss: 0.0134\n",
      "Epoch 14/1000\n",
      "3549/3549 [==============================] - 1s 398us/step - loss: 0.0151 - val_loss: 0.0142\n",
      "Epoch 15/1000\n",
      "3549/3549 [==============================] - 1s 347us/step - loss: 0.0148 - val_loss: 0.0122\n",
      "Epoch 16/1000\n",
      "3549/3549 [==============================] - 2s 471us/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 17/1000\n",
      "3549/3549 [==============================] - 2s 437us/step - loss: 0.0136 - val_loss: 0.0114\n",
      "Epoch 18/1000\n",
      "3549/3549 [==============================] - 2s 479us/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 19/1000\n",
      "3549/3549 [==============================] - 2s 456us/step - loss: 0.0139 - val_loss: 0.0115\n",
      "Epoch 20/1000\n",
      "3549/3549 [==============================] - 2s 449us/step - loss: 0.0130 - val_loss: 0.0114\n",
      "Epoch 21/1000\n",
      "3549/3549 [==============================] - 2s 432us/step - loss: 0.0131 - val_loss: 0.0105\n",
      "Epoch 22/1000\n",
      "3549/3549 [==============================] - 2s 443us/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 23/1000\n",
      "3549/3549 [==============================] - 2s 427us/step - loss: 0.0126 - val_loss: 0.0118\n",
      "Epoch 24/1000\n",
      "3549/3549 [==============================] - 1s 310us/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 25/1000\n",
      "3549/3549 [==============================] - 1s 377us/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 26/1000\n",
      "3549/3549 [==============================] - 1s 407us/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 27/1000\n",
      "3549/3549 [==============================] - 1s 404us/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 28/1000\n",
      "3549/3549 [==============================] - 1s 393us/step - loss: 0.0117 - val_loss: 0.0098\n",
      "Epoch 29/1000\n",
      "3549/3549 [==============================] - 2s 453us/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 30/1000\n",
      "3549/3549 [==============================] - 2s 452us/step - loss: 0.0120 - val_loss: 0.0101\n",
      "Epoch 31/1000\n",
      "3549/3549 [==============================] - 2s 447us/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 32/1000\n",
      "3549/3549 [==============================] - 1s 420us/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 33/1000\n",
      "3549/3549 [==============================] - 1s 413us/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 34/1000\n",
      "3549/3549 [==============================] - 2s 458us/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 35/1000\n",
      "3549/3549 [==============================] - 2s 431us/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 36/1000\n",
      "3549/3549 [==============================] - 1s 409us/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 37/1000\n",
      "3549/3549 [==============================] - 1s 406us/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 38/1000\n",
      "3549/3549 [==============================] - 1s 408us/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 39/1000\n",
      "3549/3549 [==============================] - 1s 324us/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 40/1000\n",
      "3549/3549 [==============================] - 1s 231us/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 41/1000\n",
      "3549/3549 [==============================] - 1s 355us/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 42/1000\n",
      "3549/3549 [==============================] - 1s 385us/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 43/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 44/1000\n",
      "3549/3549 [==============================] - 1s 363us/step - loss: 0.0108 - val_loss: 0.0096\n",
      "Epoch 45/1000\n",
      "3549/3549 [==============================] - 1s 339us/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 46/1000\n",
      "3549/3549 [==============================] - 1s 365us/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 47/1000\n",
      "3549/3549 [==============================] - 1s 362us/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 48/1000\n",
      "3549/3549 [==============================] - 1s 362us/step - loss: 0.0110 - val_loss: 0.0089\n",
      "Epoch 49/1000\n",
      "3549/3549 [==============================] - 1s 386us/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 50/1000\n",
      "3549/3549 [==============================] - 1s 412us/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 51/1000\n",
      "3549/3549 [==============================] - 1s 384us/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 52/1000\n",
      "3549/3549 [==============================] - 1s 392us/step - loss: 0.0106 - val_loss: 0.0091\n",
      "Epoch 53/1000\n",
      "3549/3549 [==============================] - 1s 381us/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 54/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 55/1000\n",
      "3549/3549 [==============================] - 1s 385us/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 56/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0103 - val_loss: 0.0089\n",
      "Epoch 57/1000\n",
      "3549/3549 [==============================] - 1s 381us/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 58/1000\n",
      "3549/3549 [==============================] - 1s 384us/step - loss: 0.0103 - val_loss: 0.0092\n",
      "Epoch 59/1000\n",
      "3549/3549 [==============================] - 1s 381us/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 60/1000\n",
      "3549/3549 [==============================] - 1s 263us/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 61/1000\n",
      "3549/3549 [==============================] - 1s 290us/step - loss: 0.0106 - val_loss: 0.0089\n",
      "Epoch 62/1000\n",
      "3549/3549 [==============================] - 1s 369us/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 63/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 64/1000\n",
      "3549/3549 [==============================] - 1s 383us/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 65/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0100 - val_loss: 0.0087\n",
      "Epoch 66/1000\n",
      "3549/3549 [==============================] - 1s 383us/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 67/1000\n",
      "3549/3549 [==============================] - 1s 381us/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 68/1000\n",
      "3549/3549 [==============================] - 1s 381us/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 69/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 70/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 71/1000\n",
      "3549/3549 [==============================] - 1s 399us/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 72/1000\n",
      "3549/3549 [==============================] - 1s 411us/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 73/1000\n",
      "3549/3549 [==============================] - 1s 405us/step - loss: 0.0104 - val_loss: 0.0087\n",
      "Epoch 74/1000\n",
      "3549/3549 [==============================] - 1s 360us/step - loss: 0.0097 - val_loss: 0.0092\n",
      "Epoch 75/1000\n",
      "3549/3549 [==============================] - 1s 285us/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 76/1000\n",
      "3549/3549 [==============================] - 1s 366us/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 77/1000\n",
      "3549/3549 [==============================] - 1s 381us/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 78/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0099 - val_loss: 0.0086\n",
      "Epoch 79/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 80/1000\n",
      "3549/3549 [==============================] - 1s 419us/step - loss: 0.0102 - val_loss: 0.0089\n",
      "Epoch 81/1000\n",
      "3549/3549 [==============================] - 1s 404us/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 82/1000\n",
      "3549/3549 [==============================] - 1s 399us/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 83/1000\n",
      "3549/3549 [==============================] - 1s 402us/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 84/1000\n",
      "3549/3549 [==============================] - 1s 409us/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 85/1000\n",
      "3549/3549 [==============================] - 1s 412us/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 86/1000\n",
      "3549/3549 [==============================] - 1s 396us/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 87/1000\n",
      "3549/3549 [==============================] - 1s 385us/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 88/1000\n",
      "3549/3549 [==============================] - 1s 384us/step - loss: 0.0099 - val_loss: 0.0087\n",
      "Epoch 89/1000\n",
      "3549/3549 [==============================] - 1s 382us/step - loss: 0.0099 - val_loss: 0.0085\n",
      "Epoch 90/1000\n",
      "3549/3549 [==============================] - 1s 383us/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 91/1000\n",
      "3549/3549 [==============================] - 1s 350us/step - loss: 0.0098 - val_loss: 0.0087\n",
      "Epoch 92/1000\n",
      "3549/3549 [==============================] - 1s 329us/step - loss: 0.0105 - val_loss: 0.0087\n",
      "Epoch 93/1000\n",
      "3549/3549 [==============================] - 1s 319us/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 94/1000\n",
      "3549/3549 [==============================] - 1s 314us/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 95/1000\n",
      "3549/3549 [==============================] - 1s 325us/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 96/1000\n",
      "3549/3549 [==============================] - 1s 332us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 97/1000\n",
      "3549/3549 [==============================] - 1s 365us/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 98/1000\n",
      "3549/3549 [==============================] - 1s 376us/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 99/1000\n",
      "3549/3549 [==============================] - 1s 383us/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 100/1000\n",
      "3549/3549 [==============================] - 1s 363us/step - loss: 0.0101 - val_loss: 0.0088\n",
      "Epoch 101/1000\n",
      "3549/3549 [==============================] - 1s 342us/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 102/1000\n",
      "3549/3549 [==============================] - 1s 363us/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 103/1000\n",
      "3549/3549 [==============================] - 1s 411us/step - loss: 0.0098 - val_loss: 0.0086\n",
      "Epoch 104/1000\n",
      "3549/3549 [==============================] - 1s 417us/step - loss: 0.0099 - val_loss: 0.0096\n",
      "Epoch 105/1000\n",
      "3549/3549 [==============================] - 1s 404us/step - loss: 0.0096 - val_loss: 0.0088\n",
      "Epoch 106/1000\n",
      "3549/3549 [==============================] - 1s 404us/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 107/1000\n",
      "3549/3549 [==============================] - 1s 379us/step - loss: 0.0098 - val_loss: 0.0094\n",
      "Epoch 108/1000\n",
      "3549/3549 [==============================] - 1s 338us/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 109/1000\n",
      "3549/3549 [==============================] - 1s 347us/step - loss: 0.0097 - val_loss: 0.0085\n",
      "Epoch 110/1000\n",
      "3549/3549 [==============================] - 1s 386us/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 111/1000\n",
      "3549/3549 [==============================] - 1s 400us/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 112/1000\n",
      "3549/3549 [==============================] - 1s 400us/step - loss: 0.0100 - val_loss: 0.0089\n",
      "Epoch 113/1000\n",
      "3549/3549 [==============================] - 1s 396us/step - loss: 0.0098 - val_loss: 0.0085\n",
      "Epoch 114/1000\n",
      "3549/3549 [==============================] - 1s 403us/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 115/1000\n",
      "3549/3549 [==============================] - 1s 393us/step - loss: 0.0100 - val_loss: 0.0088\n",
      "Epoch 116/1000\n",
      "3549/3549 [==============================] - 1s 344us/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 117/1000\n",
      "3549/3549 [==============================] - 1s 363us/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 118/1000\n",
      "3549/3549 [==============================] - 1s 363us/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 119/1000\n",
      "3549/3549 [==============================] - 1s 417us/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 120/1000\n",
      "3549/3549 [==============================] - 2s 430us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 121/1000\n",
      "3549/3549 [==============================] - 1s 421us/step - loss: 0.0098 - val_loss: 0.0090\n",
      "Epoch 122/1000\n",
      "3549/3549 [==============================] - 1s 368us/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 123/1000\n",
      "3549/3549 [==============================] - 1s 360us/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 124/1000\n",
      "3549/3549 [==============================] - 2s 435us/step - loss: 0.0096 - val_loss: 0.0086\n",
      "Epoch 125/1000\n",
      "3549/3549 [==============================] - 1s 411us/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 126/1000\n",
      "3549/3549 [==============================] - 1s 405us/step - loss: 0.0100 - val_loss: 0.0090\n",
      "Epoch 127/1000\n",
      "3549/3549 [==============================] - 1s 407us/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 128/1000\n",
      "3549/3549 [==============================] - 1s 406us/step - loss: 0.0099 - val_loss: 0.0088\n",
      "Epoch 129/1000\n",
      "3549/3549 [==============================] - 1s 400us/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 130/1000\n",
      "3549/3549 [==============================] - 1s 403us/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 131/1000\n",
      "3549/3549 [==============================] - 2s 440us/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 132/1000\n",
      "3549/3549 [==============================] - 1s 421us/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 133/1000\n",
      "3549/3549 [==============================] - 1s 415us/step - loss: 0.0098 - val_loss: 0.0089\n",
      "Epoch 134/1000\n",
      "3549/3549 [==============================] - 1s 420us/step - loss: 0.0097 - val_loss: 0.0088\n",
      "Epoch 135/1000\n",
      "3549/3549 [==============================] - 2s 430us/step - loss: 0.0095 - val_loss: 0.0088\n",
      "Epoch 136/1000\n",
      "3549/3549 [==============================] - 1s 376us/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 137/1000\n",
      "3549/3549 [==============================] - 1s 249us/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 138/1000\n",
      "3549/3549 [==============================] - 1s 258us/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 139/1000\n",
      "3549/3549 [==============================] - 1s 376us/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 140/1000\n",
      "3549/3549 [==============================] - 1s 419us/step - loss: 0.0096 - val_loss: 0.0092\n",
      "Epoch 141/1000\n",
      "3549/3549 [==============================] - 2s 434us/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 142/1000\n",
      "3549/3549 [==============================] - 1s 406us/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 143/1000\n",
      "3549/3549 [==============================] - 1s 402us/step - loss: 0.0094 - val_loss: 0.0102\n",
      "Epoch 144/1000\n",
      "3549/3549 [==============================] - 2s 439us/step - loss: 0.0097 - val_loss: 0.0087\n",
      "Epoch 145/1000\n",
      "3549/3549 [==============================] - 2s 427us/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3549/3549 [==============================] - 1s 326us/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 147/1000\n",
      "3549/3549 [==============================] - 1s 373us/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 148/1000\n",
      "3549/3549 [==============================] - 1s 405us/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 149/1000\n",
      "3549/3549 [==============================] - 1s 398us/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 150/1000\n",
      "3549/3549 [==============================] - 1s 419us/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 151/1000\n",
      "3549/3549 [==============================] - 1s 399us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 152/1000\n",
      "3549/3549 [==============================] - 1s 383us/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 153/1000\n",
      "3549/3549 [==============================] - 1s 399us/step - loss: 0.0097 - val_loss: 0.0091\n",
      "Epoch 154/1000\n",
      "3549/3549 [==============================] - 1s 397us/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 155/1000\n",
      "3549/3549 [==============================] - 1s 392us/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00155: early stopping\n",
      "(420, 5)\n",
      "(420, 5)\n",
      "(3942, 16, 1)\n",
      "(3942, 7)\n",
      "Train on 3547 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3547/3547 [==============================] - 2s 466us/step - loss: 0.1589 - val_loss: 0.0515\n",
      "Epoch 2/1000\n",
      "3547/3547 [==============================] - 1s 379us/step - loss: 0.0391 - val_loss: 0.0235\n",
      "Epoch 3/1000\n",
      "3547/3547 [==============================] - 1s 405us/step - loss: 0.0350 - val_loss: 0.0249\n",
      "Epoch 4/1000\n",
      "3547/3547 [==============================] - 1s 403us/step - loss: 0.0329 - val_loss: 0.0338\n",
      "Epoch 5/1000\n",
      "3547/3547 [==============================] - 1s 403us/step - loss: 0.0316 - val_loss: 0.0397\n",
      "Epoch 6/1000\n",
      "3547/3547 [==============================] - 1s 403us/step - loss: 0.0287 - val_loss: 0.0290\n",
      "Epoch 7/1000\n",
      "3547/3547 [==============================] - 1s 406us/step - loss: 0.0265 - val_loss: 0.0237\n",
      "Epoch 8/1000\n",
      "3547/3547 [==============================] - 1s 415us/step - loss: 0.0250 - val_loss: 0.0231\n",
      "Epoch 9/1000\n",
      "3547/3547 [==============================] - 1s 342us/step - loss: 0.0230 - val_loss: 0.0186\n",
      "Epoch 10/1000\n",
      "3547/3547 [==============================] - 1s 356us/step - loss: 0.0216 - val_loss: 0.0167\n",
      "Epoch 11/1000\n",
      "3547/3547 [==============================] - 1s 369us/step - loss: 0.0209 - val_loss: 0.0154\n",
      "Epoch 12/1000\n",
      "3547/3547 [==============================] - 1s 372us/step - loss: 0.0194 - val_loss: 0.0152\n",
      "Epoch 13/1000\n",
      "3547/3547 [==============================] - 1s 369us/step - loss: 0.0193 - val_loss: 0.0157\n",
      "Epoch 14/1000\n",
      "3547/3547 [==============================] - 1s 388us/step - loss: 0.0180 - val_loss: 0.0158\n",
      "Epoch 15/1000\n",
      "3547/3547 [==============================] - 1s 420us/step - loss: 0.0177 - val_loss: 0.0152\n",
      "Epoch 16/1000\n",
      "3547/3547 [==============================] - 2s 476us/step - loss: 0.0171 - val_loss: 0.0141\n",
      "Epoch 17/1000\n",
      "3547/3547 [==============================] - 2s 433us/step - loss: 0.0169 - val_loss: 0.0145\n",
      "Epoch 18/1000\n",
      "3547/3547 [==============================] - 1s 415us/step - loss: 0.0169 - val_loss: 0.0142\n",
      "Epoch 19/1000\n",
      "3547/3547 [==============================] - 1s 413us/step - loss: 0.0163 - val_loss: 0.0149\n",
      "Epoch 20/1000\n",
      "3547/3547 [==============================] - 1s 414us/step - loss: 0.0161 - val_loss: 0.0142\n",
      "Epoch 21/1000\n",
      "3547/3547 [==============================] - 1s 412us/step - loss: 0.0155 - val_loss: 0.0138\n",
      "Epoch 22/1000\n",
      "3547/3547 [==============================] - 1s 412us/step - loss: 0.0161 - val_loss: 0.0135\n",
      "Epoch 23/1000\n",
      "3547/3547 [==============================] - 1s 412us/step - loss: 0.0152 - val_loss: 0.0129\n",
      "Epoch 24/1000\n",
      "3547/3547 [==============================] - 1s 401us/step - loss: 0.0150 - val_loss: 0.0130\n",
      "Epoch 25/1000\n",
      "3547/3547 [==============================] - 1s 290us/step - loss: 0.0149 - val_loss: 0.0129\n",
      "Epoch 26/1000\n",
      "3547/3547 [==============================] - 1s 293us/step - loss: 0.0149 - val_loss: 0.0131\n",
      "Epoch 27/1000\n",
      "3547/3547 [==============================] - 1s 377us/step - loss: 0.0149 - val_loss: 0.0130\n",
      "Epoch 28/1000\n",
      "3547/3547 [==============================] - 1s 418us/step - loss: 0.0146 - val_loss: 0.0128\n",
      "Epoch 29/1000\n",
      "3547/3547 [==============================] - 2s 449us/step - loss: 0.0147 - val_loss: 0.0129\n",
      "Epoch 30/1000\n",
      "3547/3547 [==============================] - 2s 455us/step - loss: 0.0147 - val_loss: 0.0128\n",
      "Epoch 31/1000\n",
      "3547/3547 [==============================] - 1s 413us/step - loss: 0.0141 - val_loss: 0.0129\n",
      "Epoch 32/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 33/1000\n",
      "3547/3547 [==============================] - 1s 337us/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 34/1000\n",
      "3547/3547 [==============================] - 1s 402us/step - loss: 0.0140 - val_loss: 0.0127\n",
      "Epoch 35/1000\n",
      "3547/3547 [==============================] - 1s 389us/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 36/1000\n",
      "3547/3547 [==============================] - 1s 389us/step - loss: 0.0140 - val_loss: 0.0129\n",
      "Epoch 37/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0142 - val_loss: 0.0124\n",
      "Epoch 38/1000\n",
      "3547/3547 [==============================] - 1s 387us/step - loss: 0.0141 - val_loss: 0.0121\n",
      "Epoch 39/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0138 - val_loss: 0.0123\n",
      "Epoch 40/1000\n",
      "3547/3547 [==============================] - 1s 392us/step - loss: 0.0138 - val_loss: 0.0121\n",
      "Epoch 41/1000\n",
      "3547/3547 [==============================] - 1s 410us/step - loss: 0.0131 - val_loss: 0.0122\n",
      "Epoch 42/1000\n",
      "3547/3547 [==============================] - 1s 286us/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 43/1000\n",
      "3547/3547 [==============================] - 1s 379us/step - loss: 0.0135 - val_loss: 0.0122\n",
      "Epoch 44/1000\n",
      "3547/3547 [==============================] - 1s 404us/step - loss: 0.0133 - val_loss: 0.0118\n",
      "Epoch 45/1000\n",
      "3547/3547 [==============================] - 1s 402us/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 46/1000\n",
      "3547/3547 [==============================] - 1s 402us/step - loss: 0.0132 - val_loss: 0.0122\n",
      "Epoch 47/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0134 - val_loss: 0.0124\n",
      "Epoch 48/1000\n",
      "3547/3547 [==============================] - 1s 414us/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 49/1000\n",
      "3547/3547 [==============================] - 2s 441us/step - loss: 0.0132 - val_loss: 0.0120\n",
      "Epoch 50/1000\n",
      "3547/3547 [==============================] - 1s 411us/step - loss: 0.0136 - val_loss: 0.0122\n",
      "Epoch 51/1000\n",
      "3547/3547 [==============================] - 1s 419us/step - loss: 0.0131 - val_loss: 0.0120\n",
      "Epoch 52/1000\n",
      "3547/3547 [==============================] - 1s 408us/step - loss: 0.0132 - val_loss: 0.0119\n",
      "Epoch 53/1000\n",
      "3547/3547 [==============================] - 2s 424us/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 54/1000\n",
      "3547/3547 [==============================] - 2s 439us/step - loss: 0.0128 - val_loss: 0.0121\n",
      "Epoch 55/1000\n",
      "3547/3547 [==============================] - 1s 418us/step - loss: 0.0130 - val_loss: 0.0119\n",
      "Epoch 56/1000\n",
      "3547/3547 [==============================] - 2s 442us/step - loss: 0.0128 - val_loss: 0.0119\n",
      "Epoch 57/1000\n",
      "3547/3547 [==============================] - 1s 405us/step - loss: 0.0127 - val_loss: 0.0121\n",
      "Epoch 58/1000\n",
      "3547/3547 [==============================] - 1s 406us/step - loss: 0.0129 - val_loss: 0.0126\n",
      "Epoch 59/1000\n",
      "3547/3547 [==============================] - 1s 394us/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 60/1000\n",
      "3547/3547 [==============================] - 2s 436us/step - loss: 0.0131 - val_loss: 0.0121\n",
      "Epoch 61/1000\n",
      "3547/3547 [==============================] - 1s 413us/step - loss: 0.0129 - val_loss: 0.0122\n",
      "Epoch 62/1000\n",
      "3547/3547 [==============================] - 1s 391us/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 63/1000\n",
      "3547/3547 [==============================] - 1s 405us/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 64/1000\n",
      "3547/3547 [==============================] - 1s 382us/step - loss: 0.0130 - val_loss: 0.0120\n",
      "Epoch 65/1000\n",
      "3547/3547 [==============================] - 1s 383us/step - loss: 0.0130 - val_loss: 0.0135\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547/3547 [==============================] - 1s 383us/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 67/1000\n",
      "3547/3547 [==============================] - 1s 382us/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 68/1000\n",
      "3547/3547 [==============================] - 1s 383us/step - loss: 0.0126 - val_loss: 0.0126\n",
      "Epoch 69/1000\n",
      "3547/3547 [==============================] - 1s 383us/step - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 70/1000\n",
      "3547/3547 [==============================] - 1s 398us/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 71/1000\n",
      "3547/3547 [==============================] - 1s 407us/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 72/1000\n",
      "3547/3547 [==============================] - 1s 401us/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 73/1000\n",
      "3547/3547 [==============================] - 1s 387us/step - loss: 0.0127 - val_loss: 0.0137\n",
      "Epoch 74/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0128 - val_loss: 0.0124\n",
      "Epoch 75/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0125 - val_loss: 0.0133\n",
      "Epoch 76/1000\n",
      "3547/3547 [==============================] - 1s 385us/step - loss: 0.0126 - val_loss: 0.0122\n",
      "Epoch 77/1000\n",
      "3547/3547 [==============================] - 1s 406us/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 78/1000\n",
      "3547/3547 [==============================] - 1s 408us/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 79/1000\n",
      "3547/3547 [==============================] - 1s 399us/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 80/1000\n",
      "3547/3547 [==============================] - 1s 397us/step - loss: 0.0127 - val_loss: 0.0132\n",
      "Epoch 81/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0126 - val_loss: 0.0151\n",
      "Epoch 82/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0131 - val_loss: 0.0125\n",
      "Epoch 83/1000\n",
      "3547/3547 [==============================] - 1s 389us/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 84/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0122 - val_loss: 0.0130\n",
      "Epoch 85/1000\n",
      "3547/3547 [==============================] - 1s 420us/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 86/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0125 - val_loss: 0.0130\n",
      "Epoch 87/1000\n",
      "3547/3547 [==============================] - 2s 433us/step - loss: 0.0127 - val_loss: 0.0134\n",
      "Epoch 88/1000\n",
      "3547/3547 [==============================] - 2s 445us/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 89/1000\n",
      "3547/3547 [==============================] - 1s 422us/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 90/1000\n",
      "3547/3547 [==============================] - 1s 406us/step - loss: 0.0128 - val_loss: 0.0138\n",
      "Epoch 91/1000\n",
      "3547/3547 [==============================] - 1s 420us/step - loss: 0.0124 - val_loss: 0.0135\n",
      "Epoch 92/1000\n",
      "3547/3547 [==============================] - 2s 442us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 93/1000\n",
      "3547/3547 [==============================] - 1s 398us/step - loss: 0.0128 - val_loss: 0.0131\n",
      "Epoch 94/1000\n",
      "3547/3547 [==============================] - 2s 467us/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 95/1000\n",
      "3547/3547 [==============================] - 1s 394us/step - loss: 0.0123 - val_loss: 0.0141\n",
      "Epoch 96/1000\n",
      "3547/3547 [==============================] - 2s 441us/step - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 97/1000\n",
      "3547/3547 [==============================] - 2s 449us/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 98/1000\n",
      "3547/3547 [==============================] - 2s 424us/step - loss: 0.0122 - val_loss: 0.0128\n",
      "Epoch 99/1000\n",
      "3547/3547 [==============================] - 1s 362us/step - loss: 0.0127 - val_loss: 0.0142\n",
      "Epoch 100/1000\n",
      "3547/3547 [==============================] - 1s 225us/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 101/1000\n",
      "3547/3547 [==============================] - 1s 353us/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 102/1000\n",
      "3547/3547 [==============================] - 1s 390us/step - loss: 0.0126 - val_loss: 0.0129\n",
      "Epoch 103/1000\n",
      "3547/3547 [==============================] - 1s 387us/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 104/1000\n",
      "3547/3547 [==============================] - 1s 373us/step - loss: 0.0126 - val_loss: 0.0142\n",
      "Epoch 105/1000\n",
      "3547/3547 [==============================] - 1s 345us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 106/1000\n",
      "3547/3547 [==============================] - 2s 430us/step - loss: 0.0128 - val_loss: 0.0133\n",
      "Epoch 107/1000\n",
      "3547/3547 [==============================] - 1s 412us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 108/1000\n",
      "3547/3547 [==============================] - 2s 428us/step - loss: 0.0123 - val_loss: 0.0129\n",
      "Epoch 109/1000\n",
      "3547/3547 [==============================] - 1s 414us/step - loss: 0.0123 - val_loss: 0.0132\n",
      "Epoch 110/1000\n",
      "3547/3547 [==============================] - 2s 429us/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 111/1000\n",
      "3547/3547 [==============================] - 1s 418us/step - loss: 0.0122 - val_loss: 0.0125\n",
      "Epoch 112/1000\n",
      "3547/3547 [==============================] - 1s 409us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 113/1000\n",
      "3547/3547 [==============================] - 1s 413us/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 114/1000\n",
      "3547/3547 [==============================] - 1s 409us/step - loss: 0.0121 - val_loss: 0.0139\n",
      "Epoch 115/1000\n",
      "3547/3547 [==============================] - 1s 382us/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 116/1000\n",
      "3547/3547 [==============================] - 1s 278us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 117/1000\n",
      "3547/3547 [==============================] - 1s 278us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 118/1000\n",
      "3547/3547 [==============================] - 1s 287us/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 119/1000\n",
      "3547/3547 [==============================] - 1s 357us/step - loss: 0.0125 - val_loss: 0.0145\n",
      "Epoch 120/1000\n",
      "3547/3547 [==============================] - 1s 379us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 121/1000\n",
      "3547/3547 [==============================] - 1s 393us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 122/1000\n",
      "3547/3547 [==============================] - 1s 351us/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Epoch 123/1000\n",
      "3547/3547 [==============================] - 1s 393us/step - loss: 0.0122 - val_loss: 0.0149\n",
      "Epoch 124/1000\n",
      "3547/3547 [==============================] - 1s 406us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 125/1000\n",
      "3547/3547 [==============================] - 1s 387us/step - loss: 0.0125 - val_loss: 0.0132\n",
      "Epoch 126/1000\n",
      "3547/3547 [==============================] - 1s 387us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 127/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 128/1000\n",
      "3547/3547 [==============================] - 1s 385us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 129/1000\n",
      "3547/3547 [==============================] - 1s 384us/step - loss: 0.0122 - val_loss: 0.0118\n",
      "Epoch 130/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0123 - val_loss: 0.0149\n",
      "Epoch 131/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 132/1000\n",
      "3547/3547 [==============================] - 1s 387us/step - loss: 0.0122 - val_loss: 0.0145\n",
      "Epoch 133/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0122 - val_loss: 0.0142\n",
      "Epoch 134/1000\n",
      "3547/3547 [==============================] - 1s 394us/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 135/1000\n",
      "3547/3547 [==============================] - 1s 404us/step - loss: 0.0122 - val_loss: 0.0130\n",
      "Epoch 136/1000\n",
      "3547/3547 [==============================] - 1s 389us/step - loss: 0.0119 - val_loss: 0.0142\n",
      "Epoch 137/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0123 - val_loss: 0.0136\n",
      "Epoch 138/1000\n",
      "3547/3547 [==============================] - 1s 385us/step - loss: 0.0124 - val_loss: 0.0131\n",
      "Epoch 139/1000\n",
      "3547/3547 [==============================] - 1s 385us/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 140/1000\n",
      "3547/3547 [==============================] - 1s 389us/step - loss: 0.0121 - val_loss: 0.0131\n",
      "Epoch 141/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0119 - val_loss: 0.0153\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547/3547 [==============================] - 1s 383us/step - loss: 0.0123 - val_loss: 0.0135\n",
      "Epoch 143/1000\n",
      "3547/3547 [==============================] - 1s 420us/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 144/1000\n",
      "3547/3547 [==============================] - 1s 386us/step - loss: 0.0123 - val_loss: 0.0139\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00144: early stopping\n",
      "(418, 7)\n",
      "(418, 7)\n",
      "(3939, 16, 1)\n",
      "(3939, 10)\n",
      "Train on 3545 samples, validate on 394 samples\n",
      "Epoch 1/1000\n",
      "3545/3545 [==============================] - 2s 440us/step - loss: 0.1979 - val_loss: 0.0769\n",
      "Epoch 2/1000\n",
      "3545/3545 [==============================] - 1s 373us/step - loss: 0.0522 - val_loss: 0.0371\n",
      "Epoch 3/1000\n",
      "3545/3545 [==============================] - 1s 418us/step - loss: 0.0436 - val_loss: 0.0287\n",
      "Epoch 4/1000\n",
      "3545/3545 [==============================] - 1s 407us/step - loss: 0.0398 - val_loss: 0.0322\n",
      "Epoch 5/1000\n",
      "3545/3545 [==============================] - 1s 400us/step - loss: 0.0370 - val_loss: 0.0286\n",
      "Epoch 6/1000\n",
      "3545/3545 [==============================] - 1s 411us/step - loss: 0.0341 - val_loss: 0.0248\n",
      "Epoch 7/1000\n",
      "3545/3545 [==============================] - 1s 405us/step - loss: 0.0310 - val_loss: 0.0242\n",
      "Epoch 8/1000\n",
      "3545/3545 [==============================] - 1s 405us/step - loss: 0.0300 - val_loss: 0.0214\n",
      "Epoch 9/1000\n",
      "3545/3545 [==============================] - 1s 421us/step - loss: 0.0278 - val_loss: 0.0210\n",
      "Epoch 10/1000\n",
      "3545/3545 [==============================] - 1s 406us/step - loss: 0.0257 - val_loss: 0.0196\n",
      "Epoch 11/1000\n",
      "3545/3545 [==============================] - 1s 412us/step - loss: 0.0250 - val_loss: 0.0195\n",
      "Epoch 12/1000\n",
      "3545/3545 [==============================] - 1s 419us/step - loss: 0.0250 - val_loss: 0.0195\n",
      "Epoch 13/1000\n",
      "3545/3545 [==============================] - 1s 399us/step - loss: 0.0239 - val_loss: 0.0195\n",
      "Epoch 14/1000\n",
      "3545/3545 [==============================] - 1s 397us/step - loss: 0.0228 - val_loss: 0.0189\n",
      "Epoch 15/1000\n",
      "3545/3545 [==============================] - 1s 423us/step - loss: 0.0220 - val_loss: 0.0192\n",
      "Epoch 16/1000\n",
      "3545/3545 [==============================] - 1s 416us/step - loss: 0.0219 - val_loss: 0.0194\n",
      "Epoch 17/1000\n",
      "3545/3545 [==============================] - 1s 417us/step - loss: 0.0214 - val_loss: 0.0189\n",
      "Epoch 18/1000\n",
      "3545/3545 [==============================] - 1s 412us/step - loss: 0.0208 - val_loss: 0.0192\n",
      "Epoch 19/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0211 - val_loss: 0.0193\n",
      "Epoch 20/1000\n",
      "3545/3545 [==============================] - 1s 411us/step - loss: 0.0208 - val_loss: 0.0190\n",
      "Epoch 21/1000\n",
      "3545/3545 [==============================] - 1s 413us/step - loss: 0.0204 - val_loss: 0.0182\n",
      "Epoch 22/1000\n",
      "3545/3545 [==============================] - 2s 425us/step - loss: 0.0201 - val_loss: 0.0187\n",
      "Epoch 23/1000\n",
      "3545/3545 [==============================] - 1s 415us/step - loss: 0.0202 - val_loss: 0.0190\n",
      "Epoch 24/1000\n",
      "3545/3545 [==============================] - 2s 425us/step - loss: 0.0203 - val_loss: 0.0187\n",
      "Epoch 25/1000\n",
      "3545/3545 [==============================] - 1s 417us/step - loss: 0.0195 - val_loss: 0.0183\n",
      "Epoch 26/1000\n",
      "3545/3545 [==============================] - 1s 409us/step - loss: 0.0196 - val_loss: 0.0191\n",
      "Epoch 27/1000\n",
      "3545/3545 [==============================] - 1s 415us/step - loss: 0.0197 - val_loss: 0.0183\n",
      "Epoch 28/1000\n",
      "3545/3545 [==============================] - 1s 414us/step - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 29/1000\n",
      "3545/3545 [==============================] - 1s 403us/step - loss: 0.0188 - val_loss: 0.0181\n",
      "Epoch 30/1000\n",
      "3545/3545 [==============================] - 1s 392us/step - loss: 0.0190 - val_loss: 0.0190\n",
      "Epoch 31/1000\n",
      "3545/3545 [==============================] - 1s 418us/step - loss: 0.0189 - val_loss: 0.0188\n",
      "Epoch 32/1000\n",
      "3545/3545 [==============================] - 1s 418us/step - loss: 0.0184 - val_loss: 0.0183\n",
      "Epoch 33/1000\n",
      "3545/3545 [==============================] - 1s 387us/step - loss: 0.0183 - val_loss: 0.0182\n",
      "Epoch 34/1000\n",
      "3545/3545 [==============================] - 1s 388us/step - loss: 0.0185 - val_loss: 0.0189\n",
      "Epoch 35/1000\n",
      "3545/3545 [==============================] - 1s 401us/step - loss: 0.0186 - val_loss: 0.0177\n",
      "Epoch 36/1000\n",
      "3545/3545 [==============================] - 1s 402us/step - loss: 0.0181 - val_loss: 0.0175\n",
      "Epoch 37/1000\n",
      "3545/3545 [==============================] - 1s 409us/step - loss: 0.0178 - val_loss: 0.0180\n",
      "Epoch 38/1000\n",
      "3545/3545 [==============================] - 1s 385us/step - loss: 0.0182 - val_loss: 0.0184\n",
      "Epoch 39/1000\n",
      "3545/3545 [==============================] - 1s 390us/step - loss: 0.0181 - val_loss: 0.0174\n",
      "Epoch 40/1000\n",
      "3545/3545 [==============================] - 1s 388us/step - loss: 0.0182 - val_loss: 0.0178\n",
      "Epoch 41/1000\n",
      "3545/3545 [==============================] - 1s 388us/step - loss: 0.0179 - val_loss: 0.0177\n",
      "Epoch 42/1000\n",
      "3545/3545 [==============================] - 1s 386us/step - loss: 0.0173 - val_loss: 0.0180\n",
      "Epoch 43/1000\n",
      "3545/3545 [==============================] - 1s 387us/step - loss: 0.0176 - val_loss: 0.0183\n",
      "Epoch 44/1000\n",
      "3545/3545 [==============================] - 1s 402us/step - loss: 0.0171 - val_loss: 0.0181\n",
      "Epoch 45/1000\n",
      "3545/3545 [==============================] - 1s 388us/step - loss: 0.0172 - val_loss: 0.0176\n",
      "Epoch 46/1000\n",
      "3545/3545 [==============================] - 1s 388us/step - loss: 0.0175 - val_loss: 0.0181\n",
      "Epoch 47/1000\n",
      "3545/3545 [==============================] - 1s 273us/step - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 48/1000\n",
      "3545/3545 [==============================] - 1s 242us/step - loss: 0.0173 - val_loss: 0.0177\n",
      "Epoch 49/1000\n",
      "3545/3545 [==============================] - 1s 361us/step - loss: 0.0175 - val_loss: 0.0170\n",
      "Epoch 50/1000\n",
      "3545/3545 [==============================] - 1s 393us/step - loss: 0.0171 - val_loss: 0.0169\n",
      "Epoch 51/1000\n",
      "3545/3545 [==============================] - 1s 388us/step - loss: 0.0166 - val_loss: 0.0177\n",
      "Epoch 52/1000\n",
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 53/1000\n",
      "3545/3545 [==============================] - 1s 401us/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 54/1000\n",
      "3545/3545 [==============================] - 1s 363us/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 55/1000\n",
      "3545/3545 [==============================] - 1s 407us/step - loss: 0.0172 - val_loss: 0.0180\n",
      "Epoch 56/1000\n",
      "3545/3545 [==============================] - 1s 412us/step - loss: 0.0167 - val_loss: 0.0166\n",
      "Epoch 57/1000\n",
      "3545/3545 [==============================] - 1s 396us/step - loss: 0.0170 - val_loss: 0.0180\n",
      "Epoch 58/1000\n",
      "3545/3545 [==============================] - 1s 393us/step - loss: 0.0172 - val_loss: 0.0170\n",
      "Epoch 59/1000\n",
      "3545/3545 [==============================] - 1s 398us/step - loss: 0.0168 - val_loss: 0.0173\n",
      "Epoch 60/1000\n",
      "3545/3545 [==============================] - 1s 415us/step - loss: 0.0169 - val_loss: 0.0178\n",
      "Epoch 61/1000\n",
      "3545/3545 [==============================] - 1s 306us/step - loss: 0.0165 - val_loss: 0.0186\n",
      "Epoch 62/1000\n",
      "3545/3545 [==============================] - 1s 381us/step - loss: 0.0169 - val_loss: 0.0195\n",
      "Epoch 63/1000\n",
      "3545/3545 [==============================] - 1s 399us/step - loss: 0.0172 - val_loss: 0.0193\n",
      "Epoch 64/1000\n",
      "3545/3545 [==============================] - 2s 429us/step - loss: 0.0167 - val_loss: 0.0172\n",
      "Epoch 65/1000\n",
      "3545/3545 [==============================] - 1s 394us/step - loss: 0.0166 - val_loss: 0.0193\n",
      "Epoch 66/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0168 - val_loss: 0.0192\n",
      "Epoch 67/1000\n",
      "3545/3545 [==============================] - 1s 417us/step - loss: 0.0166 - val_loss: 0.0179\n",
      "Epoch 68/1000\n",
      "3545/3545 [==============================] - 1s 419us/step - loss: 0.0164 - val_loss: 0.0205\n",
      "Epoch 69/1000\n",
      "3545/3545 [==============================] - 2s 435us/step - loss: 0.0165 - val_loss: 0.0198\n",
      "Epoch 70/1000\n",
      "3545/3545 [==============================] - 1s 395us/step - loss: 0.0165 - val_loss: 0.0194\n",
      "Epoch 71/1000\n",
      "3545/3545 [==============================] - 1s 381us/step - loss: 0.0164 - val_loss: 0.0192\n",
      "Epoch 72/1000\n",
      "3545/3545 [==============================] - 1s 375us/step - loss: 0.0166 - val_loss: 0.0196\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0164 - val_loss: 0.0214\n",
      "Epoch 74/1000\n",
      "3545/3545 [==============================] - 2s 427us/step - loss: 0.0164 - val_loss: 0.0206\n",
      "Epoch 75/1000\n",
      "3545/3545 [==============================] - 1s 417us/step - loss: 0.0162 - val_loss: 0.0212\n",
      "Epoch 76/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0166 - val_loss: 0.0208\n",
      "Epoch 77/1000\n",
      "3545/3545 [==============================] - 1s 394us/step - loss: 0.0160 - val_loss: 0.0204\n",
      "Epoch 78/1000\n",
      "3545/3545 [==============================] - 1s 393us/step - loss: 0.0162 - val_loss: 0.0192\n",
      "Epoch 79/1000\n",
      "3545/3545 [==============================] - 1s 421us/step - loss: 0.0162 - val_loss: 0.0191\n",
      "Epoch 80/1000\n",
      "3545/3545 [==============================] - 1s 395us/step - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 81/1000\n",
      "3545/3545 [==============================] - 1s 410us/step - loss: 0.0162 - val_loss: 0.0194\n",
      "Epoch 82/1000\n",
      "3545/3545 [==============================] - 1s 423us/step - loss: 0.0164 - val_loss: 0.0209\n",
      "Epoch 83/1000\n",
      "3545/3545 [==============================] - 1s 393us/step - loss: 0.0161 - val_loss: 0.0196\n",
      "Epoch 84/1000\n",
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0159 - val_loss: 0.0200\n",
      "Epoch 85/1000\n",
      "3545/3545 [==============================] - 1s 390us/step - loss: 0.0162 - val_loss: 0.0211\n",
      "Epoch 86/1000\n",
      "3545/3545 [==============================] - 1s 392us/step - loss: 0.0159 - val_loss: 0.0215\n",
      "Epoch 87/1000\n",
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 88/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0162 - val_loss: 0.0201\n",
      "Epoch 89/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0160 - val_loss: 0.0199\n",
      "Epoch 90/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0161 - val_loss: 0.0190\n",
      "Epoch 91/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0162 - val_loss: 0.0229\n",
      "Epoch 92/1000\n",
      "3545/3545 [==============================] - 1s 390us/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Epoch 93/1000\n",
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0161 - val_loss: 0.0214\n",
      "Epoch 94/1000\n",
      "3545/3545 [==============================] - 1s 405us/step - loss: 0.0163 - val_loss: 0.0201\n",
      "Epoch 95/1000\n",
      "3545/3545 [==============================] - 1s 393us/step - loss: 0.0164 - val_loss: 0.0206\n",
      "Epoch 96/1000\n",
      "3545/3545 [==============================] - 1s 392us/step - loss: 0.0165 - val_loss: 0.0197\n",
      "Epoch 97/1000\n",
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0157 - val_loss: 0.0202\n",
      "Epoch 98/1000\n",
      "3545/3545 [==============================] - 1s 405us/step - loss: 0.0160 - val_loss: 0.0214\n",
      "Epoch 99/1000\n",
      "3545/3545 [==============================] - 1s 254us/step - loss: 0.0163 - val_loss: 0.0216\n",
      "Epoch 100/1000\n",
      "3545/3545 [==============================] - 1s 267us/step - loss: 0.0160 - val_loss: 0.0194\n",
      "Epoch 101/1000\n",
      "3545/3545 [==============================] - 1s 373us/step - loss: 0.0159 - val_loss: 0.0215\n",
      "Epoch 102/1000\n",
      "3545/3545 [==============================] - 1s 387us/step - loss: 0.0163 - val_loss: 0.0200\n",
      "Epoch 103/1000\n",
      "3545/3545 [==============================] - 1s 387us/step - loss: 0.0158 - val_loss: 0.0196\n",
      "Epoch 104/1000\n",
      "3545/3545 [==============================] - 1s 390us/step - loss: 0.0161 - val_loss: 0.0200\n",
      "Epoch 105/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0158 - val_loss: 0.0188\n",
      "Epoch 106/1000\n",
      "3545/3545 [==============================] - 1s 404us/step - loss: 0.0162 - val_loss: 0.0199\n",
      "Epoch 107/1000\n",
      "3545/3545 [==============================] - 1s 349us/step - loss: 0.0157 - val_loss: 0.0203\n",
      "Epoch 108/1000\n",
      "3545/3545 [==============================] - 1s 333us/step - loss: 0.0158 - val_loss: 0.0197\n",
      "Epoch 109/1000\n",
      "3545/3545 [==============================] - 1s 372us/step - loss: 0.0161 - val_loss: 0.0216\n",
      "Epoch 110/1000\n",
      "3545/3545 [==============================] - 1s 374us/step - loss: 0.0159 - val_loss: 0.0189\n",
      "Epoch 111/1000\n",
      "3545/3545 [==============================] - 1s 408us/step - loss: 0.0160 - val_loss: 0.0211\n",
      "Epoch 112/1000\n",
      "3545/3545 [==============================] - 1s 397us/step - loss: 0.0161 - val_loss: 0.0190\n",
      "Epoch 113/1000\n",
      "3545/3545 [==============================] - 1s 403us/step - loss: 0.0160 - val_loss: 0.0212\n",
      "Epoch 114/1000\n",
      "3545/3545 [==============================] - 1s 394us/step - loss: 0.0160 - val_loss: 0.0194\n",
      "Epoch 115/1000\n",
      "3545/3545 [==============================] - 1s 389us/step - loss: 0.0159 - val_loss: 0.0205\n",
      "Epoch 116/1000\n",
      "3545/3545 [==============================] - 1s 392us/step - loss: 0.0162 - val_loss: 0.0197\n",
      "Epoch 117/1000\n",
      "3545/3545 [==============================] - 1s 398us/step - loss: 0.0161 - val_loss: 0.0197\n",
      "Epoch 118/1000\n",
      "3545/3545 [==============================] - 1s 397us/step - loss: 0.0162 - val_loss: 0.0190\n",
      "Epoch 119/1000\n",
      "3545/3545 [==============================] - 1s 380us/step - loss: 0.0158 - val_loss: 0.0190\n",
      "Epoch 120/1000\n",
      "3545/3545 [==============================] - 1s 402us/step - loss: 0.0156 - val_loss: 0.0191\n",
      "Epoch 121/1000\n",
      "3545/3545 [==============================] - 1s 420us/step - loss: 0.0155 - val_loss: 0.0205\n",
      "Epoch 122/1000\n",
      "3545/3545 [==============================] - 1s 398us/step - loss: 0.0158 - val_loss: 0.0214\n",
      "Epoch 123/1000\n",
      "3545/3545 [==============================] - 1s 392us/step - loss: 0.0160 - val_loss: 0.0193\n",
      "Epoch 124/1000\n",
      "3545/3545 [==============================] - 1s 392us/step - loss: 0.0157 - val_loss: 0.0216\n",
      "Epoch 125/1000\n",
      "3545/3545 [==============================] - 1s 398us/step - loss: 0.0160 - val_loss: 0.0217\n",
      "Epoch 126/1000\n",
      "3545/3545 [==============================] - 1s 408us/step - loss: 0.0158 - val_loss: 0.0181\n",
      "Epoch 127/1000\n",
      "3545/3545 [==============================] - 1s 401us/step - loss: 0.0156 - val_loss: 0.0199\n",
      "Epoch 128/1000\n",
      "3545/3545 [==============================] - 1s 421us/step - loss: 0.0160 - val_loss: 0.0196\n",
      "Epoch 129/1000\n",
      "3545/3545 [==============================] - 2s 429us/step - loss: 0.0153 - val_loss: 0.0202\n",
      "Epoch 130/1000\n",
      "3545/3545 [==============================] - 1s 390us/step - loss: 0.0156 - val_loss: 0.0198\n",
      "Epoch 131/1000\n",
      "3545/3545 [==============================] - 1s 331us/step - loss: 0.0157 - val_loss: 0.0200\n",
      "Epoch 132/1000\n",
      "3545/3545 [==============================] - 1s 397us/step - loss: 0.0158 - val_loss: 0.0200\n",
      "Epoch 133/1000\n",
      "3545/3545 [==============================] - 1s 416us/step - loss: 0.0158 - val_loss: 0.0198\n",
      "Epoch 134/1000\n",
      "3545/3545 [==============================] - 1s 420us/step - loss: 0.0154 - val_loss: 0.0189\n",
      "Epoch 135/1000\n",
      "3545/3545 [==============================] - 1s 394us/step - loss: 0.0158 - val_loss: 0.0222\n",
      "Epoch 136/1000\n",
      "3545/3545 [==============================] - 1s 404us/step - loss: 0.0156 - val_loss: 0.0182\n",
      "Epoch 137/1000\n",
      "3545/3545 [==============================] - 2s 509us/step - loss: 0.0159 - val_loss: 0.0217\n",
      "Epoch 138/1000\n",
      "3545/3545 [==============================] - 2s 470us/step - loss: 0.0156 - val_loss: 0.0214\n",
      "Epoch 139/1000\n",
      "3545/3545 [==============================] - 2s 464us/step - loss: 0.0154 - val_loss: 0.0190\n",
      "Epoch 140/1000\n",
      "3545/3545 [==============================] - 1s 396us/step - loss: 0.0159 - val_loss: 0.0199\n",
      "Epoch 141/1000\n",
      "3545/3545 [==============================] - 1s 392us/step - loss: 0.0160 - val_loss: 0.0197\n",
      "Epoch 142/1000\n",
      "3545/3545 [==============================] - 2s 438us/step - loss: 0.0154 - val_loss: 0.0181\n",
      "Epoch 143/1000\n",
      "3545/3545 [==============================] - 1s 415us/step - loss: 0.0162 - val_loss: 0.0218\n",
      "Epoch 144/1000\n",
      "3545/3545 [==============================] - 1s 413us/step - loss: 0.0160 - val_loss: 0.0203\n",
      "Epoch 145/1000\n",
      "3545/3545 [==============================] - 1s 413us/step - loss: 0.0155 - val_loss: 0.0179\n",
      "Epoch 146/1000\n",
      "3545/3545 [==============================] - 1s 354us/step - loss: 0.0156 - val_loss: 0.0224\n",
      "Epoch 147/1000\n",
      "3545/3545 [==============================] - 1s 285us/step - loss: 0.0159 - val_loss: 0.0176\n",
      "Epoch 148/1000\n",
      "3545/3545 [==============================] - 1s 357us/step - loss: 0.0155 - val_loss: 0.0236\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0157 - val_loss: 0.0195\n",
      "Epoch 150/1000\n",
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0160 - val_loss: 0.0229\n",
      "Epoch 151/1000\n",
      "3545/3545 [==============================] - 1s 394us/step - loss: 0.0158 - val_loss: 0.0179\n",
      "Epoch 152/1000\n",
      "3545/3545 [==============================] - 1s 391us/step - loss: 0.0159 - val_loss: 0.0216\n",
      "Epoch 153/1000\n",
      "3545/3545 [==============================] - 1s 400us/step - loss: 0.0156 - val_loss: 0.0187\n",
      "Epoch 154/1000\n",
      "3545/3545 [==============================] - 2s 458us/step - loss: 0.0156 - val_loss: 0.0214\n",
      "Epoch 155/1000\n",
      "3545/3545 [==============================] - 2s 450us/step - loss: 0.0154 - val_loss: 0.0188\n",
      "Epoch 156/1000\n",
      "3545/3545 [==============================] - 2s 432us/step - loss: 0.0151 - val_loss: 0.0214\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00156: early stopping\n",
      "(415, 10)\n",
      "(415, 10)\n"
     ]
    }
   ],
   "source": [
    "for step in output_time_step:\n",
    "    \n",
    "    # Creating supervised dataset\n",
    "    in_start = 0\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(df_train_scale)):\n",
    "        in_end = in_start + input_time_step\n",
    "        out_end = in_end + step\n",
    "        if out_end < len(df_train_scale):\n",
    "            x_train.append(df_train_scale[in_start:in_end, 0])\n",
    "            y_train.append(df_train_scale[in_end:out_end, 0])\n",
    "        in_start += 1\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    # Vanilla LSTM Model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = lstm_units,input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(step))\n",
    "    model.compile(optimizer = optimizer, loss = loss)\n",
    "    \n",
    "    # Training Model\n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        validation_split = validation_split,\n",
    "                        callbacks = [callback], \n",
    "                        epochs = epoch, \n",
    "                        batch_size = batch_size, \n",
    "                        shuffle = False)\n",
    "    \n",
    "    \n",
    "    # Prediction on Test Set\n",
    "    pred_vector = np.empty((0, step))\n",
    "    real_vector = np.empty((0, step))\n",
    "\n",
    "    for i in range(df_test_scale.size):\n",
    "\n",
    "        if(i+step+input_time_step < df_test_scale.size): \n",
    "            val = df_test_scale[i:i+input_time_step]\n",
    "            #print(i, i+input_time_step)\n",
    "            val = val.reshape((1, len(val), 1))\n",
    "            #print(val.shape)\n",
    "            pred = model.predict(val)\n",
    "            pred = sc.inverse_transform(pred)\n",
    "            pred_vector = np.append(pred_vector,pred,axis=0)\n",
    "            real = df_test_scale[i+input_time_step:i+input_time_step+step].reshape(1,step)\n",
    "            #print(i+input_time_step,i+input_time_step+output_time_step)\n",
    "            real = sc.inverse_transform(real)\n",
    "            real_vector = np.append(real_vector,real,axis=0)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(pred_vector.shape)\n",
    "    print(real_vector.shape)\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    sum_mae = 0\n",
    "    sum_rmse = 0\n",
    "    for i in range(len(pred_vector)):#same as real_vector\n",
    "        mae = metrics.mean_absolute_error(real_vector[i], pred_vector[i])\n",
    "        mse = metrics.mean_squared_error(real_vector[i], pred_vector[i])\n",
    "        rmse = np.sqrt(mse)\n",
    "        sum_mae = sum_mae + mae\n",
    "        sum_rmse = sum_rmse + rmse\n",
    "\n",
    "    # Average MAE\n",
    "    avg_mae = sum_mae / len(pred_vector)\n",
    "    # Average RMSE\n",
    "    avg_rmse = sum_rmse / len(pred_vector)\n",
    "    \n",
    "    RMSE.append(avg_rmse)\n",
    "    MAE.append(avg_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0037749253784579565,\n",
       " 0.00443262461680888,\n",
       " 0.005583158343489537,\n",
       " 0.006645979512715468,\n",
       " 0.007792286910878454]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba37641f10>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output_time_step,RMSE, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0034756145388240263,\n",
       " 0.003973542586864453,\n",
       " 0.004896524176879156,\n",
       " 0.00573943484351966,\n",
       " 0.006705801703317484]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba37170210>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output_time_step,MAE, marker='o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
