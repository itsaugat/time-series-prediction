{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import LSTM, Bidirectional, Dense, Dropout, RepeatVector, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tcn import TCN\n",
    "from nbeats_keras.model import NBeatsNet\n",
    "#from attention_decoder import AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/EURGBP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>0.6627</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>0.6494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>0.6496</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.6472</td>\n",
       "      <td>0.6472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-06</td>\n",
       "      <td>0.6471</td>\n",
       "      <td>0.6523</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.6502</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>0.6498</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Open    High     Low   Close  Adj Close  Volume\n",
       "0  2003-01-01  0.6547  0.6547  0.6497  0.6504     0.6504     0.0\n",
       "1  2003-01-02  0.6503  0.6627  0.6475  0.6494     0.6494     0.0\n",
       "2  2003-01-03  0.6496  0.6516  0.6466  0.6472     0.6472     0.0\n",
       "3  2003-01-06  0.6471  0.6523  0.6467  0.6502     0.6502     0.0\n",
       "4  2003-01-07  0.6498  0.6510  0.6477  0.6490     0.6490     0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>2019-12-25</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.86070</td>\n",
       "      <td>0.84913</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>0.85520</td>\n",
       "      <td>0.85550</td>\n",
       "      <td>0.85290</td>\n",
       "      <td>0.85530</td>\n",
       "      <td>0.85530</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>0.85370</td>\n",
       "      <td>0.85632</td>\n",
       "      <td>0.85095</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.85380</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>0.85406</td>\n",
       "      <td>0.85558</td>\n",
       "      <td>0.85128</td>\n",
       "      <td>0.85406</td>\n",
       "      <td>0.85406</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.85419</td>\n",
       "      <td>0.85480</td>\n",
       "      <td>0.84544</td>\n",
       "      <td>0.85426</td>\n",
       "      <td>0.85426</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     Open     High      Low    Close  Adj Close  Volume\n",
       "4430  2019-12-25  0.85700  0.86070  0.84913  0.85700    0.85700     0.0\n",
       "4431  2019-12-26  0.85520  0.85550  0.85290  0.85530    0.85530     0.0\n",
       "4432  2019-12-27  0.85370  0.85632  0.85095  0.85380    0.85380     0.0\n",
       "4433  2019-12-30  0.85406  0.85558  0.85128  0.85406    0.85406     0.0\n",
       "4434  2019-12-31  0.85419  0.85480  0.84544  0.85426    0.85426     0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frac = 0.1\n",
    "split = len(data) - round(test_frac*len(data))\n",
    "#split\n",
    "df_train = data[:split]\n",
    "df_test = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3965\n",
      "441\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#sc = MinMaxScaler()\n",
    "sc = StandardScaler()\n",
    "df_train_scale = sc.fit_transform(df_train['Close'].values.reshape(-1,1))\n",
    "df_test_scale = sc.transform(df_test['Close'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.61547514],\n",
       "       [-1.6276607 ],\n",
       "       [-1.65446891],\n",
       "       ...,\n",
       "       [ 1.09641972],\n",
       "       [ 1.09958796],\n",
       "       [ 1.09934425]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_time_step = 16\n",
    "output_time_step = [2,3,5,7,10]\n",
    "epoch = 1000\n",
    "batch_size = 32\n",
    "validation_split=0.1\n",
    "optimizer = 'adam'\n",
    "loss = 'mean_squared_error'\n",
    "dropout = 0.1\n",
    "units = 100\n",
    "dilations=[1, 2, 4, 8]\n",
    "callback = EarlyStopping(monitor = 'val_loss', \n",
    "                         min_delta = 1e-4, \n",
    "                         patience = 100, \n",
    "                         verbose=1, \n",
    "                         mode='auto', \n",
    "                         restore_best_weights=True)\n",
    "RMSE = []\n",
    "MAE = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3947, 16, 1)\n",
      "(3947, 2)\n",
      "Train on 3552 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3552/3552 [==============================] - 7s 2ms/step - loss: 6.5020 - val_loss: 0.4690\n",
      "Epoch 2/1000\n",
      "3552/3552 [==============================] - 3s 789us/step - loss: 0.3768 - val_loss: 0.0109\n",
      "Epoch 3/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.1614 - val_loss: 0.0390\n",
      "Epoch 4/1000\n",
      "3552/3552 [==============================] - 6s 2ms/step - loss: 0.0965 - val_loss: 0.0079\n",
      "Epoch 5/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0814 - val_loss: 0.0620\n",
      "Epoch 6/1000\n",
      "3552/3552 [==============================] - 3s 942us/step - loss: 0.0525 - val_loss: 0.0069\n",
      "Epoch 7/1000\n",
      "3552/3552 [==============================] - 6s 2ms/step - loss: 0.0438 - val_loss: 0.0209\n",
      "Epoch 8/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0362 - val_loss: 0.0149\n",
      "Epoch 9/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0308 - val_loss: 0.0162\n",
      "Epoch 10/1000\n",
      "3552/3552 [==============================] - 3s 731us/step - loss: 0.0257 - val_loss: 0.0067\n",
      "Epoch 11/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0244 - val_loss: 0.0112\n",
      "Epoch 12/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0215 - val_loss: 0.0108\n",
      "Epoch 13/1000\n",
      "3552/3552 [==============================] - 3s 818us/step - loss: 0.0188 - val_loss: 0.0085\n",
      "Epoch 14/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0169 - val_loss: 0.0051\n",
      "Epoch 15/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0155 - val_loss: 0.0060\n",
      "Epoch 16/1000\n",
      "3552/3552 [==============================] - 3s 787us/step - loss: 0.0157 - val_loss: 0.0051\n",
      "Epoch 17/1000\n",
      "3552/3552 [==============================] - 3s 822us/step - loss: 0.0145 - val_loss: 0.0052\n",
      "Epoch 18/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0135 - val_loss: 0.0091\n",
      "Epoch 19/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0120 - val_loss: 0.0072\n",
      "Epoch 20/1000\n",
      "3552/3552 [==============================] - 4s 995us/step - loss: 0.0118 - val_loss: 0.0129\n",
      "Epoch 21/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0124 - val_loss: 0.0052\n",
      "Epoch 22/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0139 - val_loss: 0.0074\n",
      "Epoch 23/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0124 - val_loss: 0.0091\n",
      "Epoch 24/1000\n",
      "3552/3552 [==============================] - 2s 630us/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 25/1000\n",
      "3552/3552 [==============================] - 3s 812us/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 26/1000\n",
      "3552/3552 [==============================] - 3s 779us/step - loss: 0.0105 - val_loss: 0.0153\n",
      "Epoch 27/1000\n",
      "3552/3552 [==============================] - 2s 659us/step - loss: 0.0114 - val_loss: 0.0296\n",
      "Epoch 28/1000\n",
      "3552/3552 [==============================] - 3s 833us/step - loss: 0.0140 - val_loss: 0.0105\n",
      "Epoch 29/1000\n",
      "3552/3552 [==============================] - 3s 826us/step - loss: 0.0141 - val_loss: 0.0071\n",
      "Epoch 30/1000\n",
      "3552/3552 [==============================] - 3s 967us/step - loss: 0.0122 - val_loss: 0.0274\n",
      "Epoch 31/1000\n",
      "3552/3552 [==============================] - 4s 993us/step - loss: 0.0116 - val_loss: 0.0250\n",
      "Epoch 32/1000\n",
      "3552/3552 [==============================] - 3s 907us/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 33/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 34/1000\n",
      "3552/3552 [==============================] - 3s 778us/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 35/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0106 - val_loss: 0.0224\n",
      "Epoch 36/1000\n",
      "3552/3552 [==============================] - 3s 936us/step - loss: 0.0104 - val_loss: 0.0169\n",
      "Epoch 37/1000\n",
      "3552/3552 [==============================] - 3s 775us/step - loss: 0.0089 - val_loss: 0.0087\n",
      "Epoch 38/1000\n",
      "3552/3552 [==============================] - 3s 823us/step - loss: 0.0115 - val_loss: 0.0278\n",
      "Epoch 39/1000\n",
      "3552/3552 [==============================] - 3s 898us/step - loss: 0.0101 - val_loss: 0.0158\n",
      "Epoch 40/1000\n",
      "3552/3552 [==============================] - 3s 708us/step - loss: 0.0095 - val_loss: 0.0196\n",
      "Epoch 41/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0095 - val_loss: 0.0183\n",
      "Epoch 42/1000\n",
      "3552/3552 [==============================] - 3s 835us/step - loss: 0.0095 - val_loss: 0.0144\n",
      "Epoch 43/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0101 - val_loss: 0.0150\n",
      "Epoch 44/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0106 - val_loss: 0.0502\n",
      "Epoch 45/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0143 - val_loss: 0.0301\n",
      "Epoch 46/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0147 - val_loss: 0.0350\n",
      "Epoch 47/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0113 - val_loss: 0.0597\n",
      "Epoch 48/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0142 - val_loss: 0.0670\n",
      "Epoch 49/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0203 - val_loss: 0.0465\n",
      "Epoch 50/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0139 - val_loss: 0.0300\n",
      "Epoch 51/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0123 - val_loss: 0.0071\n",
      "Epoch 52/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0112 - val_loss: 0.0755\n",
      "Epoch 53/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0118 - val_loss: 0.0750\n",
      "Epoch 54/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0096 - val_loss: 0.0490\n",
      "Epoch 55/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0090 - val_loss: 0.0461\n",
      "Epoch 56/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0076 - val_loss: 0.0272\n",
      "Epoch 57/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0073 - val_loss: 0.0215\n",
      "Epoch 58/1000\n",
      "3552/3552 [==============================] - 6s 2ms/step - loss: 0.0071 - val_loss: 0.0298\n",
      "Epoch 59/1000\n",
      "3552/3552 [==============================] - 3s 941us/step - loss: 0.0080 - val_loss: 0.0292\n",
      "Epoch 60/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0077 - val_loss: 0.0463\n",
      "Epoch 61/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0095 - val_loss: 0.0471\n",
      "Epoch 62/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0089 - val_loss: 0.0503\n",
      "Epoch 63/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0088 - val_loss: 0.0295\n",
      "Epoch 64/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0093 - val_loss: 0.0658\n",
      "Epoch 65/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0099 - val_loss: 0.0409\n",
      "Epoch 66/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0091 - val_loss: 0.0404\n",
      "Epoch 67/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0079 - val_loss: 0.0381\n",
      "Epoch 68/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0092 - val_loss: 0.0658\n",
      "Epoch 69/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0113 - val_loss: 0.0498\n",
      "Epoch 70/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0744 - val_loss: 0.7938\n",
      "Epoch 71/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.5164 - val_loss: 0.0212\n",
      "Epoch 72/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0519 - val_loss: 0.0251\n",
      "Epoch 73/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0162 - val_loss: 0.0096\n",
      "Epoch 74/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0105 - val_loss: 0.0055\n",
      "Epoch 75/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 76/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 77/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0085 - val_loss: 0.0045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 79/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0073 - val_loss: 0.0045\n",
      "Epoch 80/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0044\n",
      "Epoch 81/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 82/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0044\n",
      "Epoch 83/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0053\n",
      "Epoch 84/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 85/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0064\n",
      "Epoch 86/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 87/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0057\n",
      "Epoch 88/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0050\n",
      "Epoch 89/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 90/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0062 - val_loss: 0.0048\n",
      "Epoch 91/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 92/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 93/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 94/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 95/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0084\n",
      "Epoch 96/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 97/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0075 - val_loss: 0.0073\n",
      "Epoch 98/1000\n",
      "3552/3552 [==============================] - 3s 764us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 99/1000\n",
      "3552/3552 [==============================] - 3s 770us/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 100/1000\n",
      "3552/3552 [==============================] - 3s 875us/step - loss: 0.0078 - val_loss: 0.0148\n",
      "Epoch 101/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 102/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 103/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0095\n",
      "Epoch 104/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0192\n",
      "Epoch 105/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0079 - val_loss: 0.0119\n",
      "Epoch 106/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 107/1000\n",
      "3552/3552 [==============================] - 3s 875us/step - loss: 0.0078 - val_loss: 0.0066\n",
      "Epoch 108/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0076 - val_loss: 0.0045\n",
      "Epoch 109/1000\n",
      "3552/3552 [==============================] - 3s 899us/step - loss: 0.0063 - val_loss: 0.0133\n",
      "Epoch 110/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 111/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 112/1000\n",
      "3552/3552 [==============================] - 3s 864us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 113/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 114/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0077 - val_loss: 0.0066\n",
      "Epoch 115/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 116/1000\n",
      "3552/3552 [==============================] - 3s 929us/step - loss: 0.0083 - val_loss: 0.0226\n",
      "Epoch 117/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 118/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 119/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0076 - val_loss: 0.0168\n",
      "Epoch 120/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0076 - val_loss: 0.0194\n",
      "Epoch 121/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0205\n",
      "Epoch 122/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 123/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 124/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0045\n",
      "Epoch 125/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0111\n",
      "Epoch 126/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 127/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0117\n",
      "Epoch 128/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 129/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0075 - val_loss: 0.0153\n",
      "Epoch 130/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0072 - val_loss: 0.0047\n",
      "Epoch 131/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0110\n",
      "Epoch 132/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 133/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 134/1000\n",
      "3552/3552 [==============================] - 5s 2ms/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 135/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 136/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0145\n",
      "Epoch 137/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0118 - val_loss: 0.0608\n",
      "Epoch 138/1000\n",
      "3552/3552 [==============================] - 3s 810us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 139/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 140/1000\n",
      "3552/3552 [==============================] - 3s 925us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 141/1000\n",
      "3552/3552 [==============================] - 3s 944us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 142/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0055 - val_loss: 0.0059\n",
      "Epoch 143/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 144/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0052 - val_loss: 0.0061\n",
      "Epoch 145/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0054 - val_loss: 0.0119\n",
      "Epoch 146/1000\n",
      "3552/3552 [==============================] - 3s 849us/step - loss: 0.0062 - val_loss: 0.0195\n",
      "Epoch 147/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 148/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0060 - val_loss: 0.0120\n",
      "Epoch 149/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0062 - val_loss: 0.0117\n",
      "Epoch 150/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0057 - val_loss: 0.0119\n",
      "Epoch 151/1000\n",
      "3552/3552 [==============================] - 3s 945us/step - loss: 0.0055 - val_loss: 0.0083\n",
      "Epoch 152/1000\n",
      "3552/3552 [==============================] - 3s 845us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 153/1000\n",
      "3552/3552 [==============================] - 3s 718us/step - loss: 0.0050 - val_loss: 0.0082\n",
      "Epoch 154/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 155/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3552/3552 [==============================] - 3s 960us/step - loss: 0.0049 - val_loss: 0.0076\n",
      "Epoch 156/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0051 - val_loss: 0.0057\n",
      "Epoch 157/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0105\n",
      "Epoch 158/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0477 - val_loss: 0.0252\n",
      "Epoch 159/1000\n",
      "3552/3552 [==============================] - 3s 720us/step - loss: 0.0272 - val_loss: 0.0639\n",
      "Epoch 160/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0104 - val_loss: 0.1005\n",
      "Epoch 161/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0090 - val_loss: 0.0525\n",
      "Epoch 162/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0082 - val_loss: 0.0444\n",
      "Epoch 163/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0074 - val_loss: 0.0231\n",
      "Epoch 164/1000\n",
      "3552/3552 [==============================] - 3s 909us/step - loss: 0.0069 - val_loss: 0.0184\n",
      "Epoch 165/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0069 - val_loss: 0.0212\n",
      "Epoch 166/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0072 - val_loss: 0.0207\n",
      "Epoch 167/1000\n",
      "3552/3552 [==============================] - 5s 1ms/step - loss: 0.0062 - val_loss: 0.0264\n",
      "Epoch 168/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0166\n",
      "Epoch 169/1000\n",
      "3552/3552 [==============================] - 3s 871us/step - loss: 0.0074 - val_loss: 0.0197\n",
      "Epoch 170/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0080 - val_loss: 0.0587\n",
      "Epoch 171/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0095 - val_loss: 0.0821\n",
      "Epoch 172/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0077 - val_loss: 0.0148\n",
      "Epoch 173/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0054 - val_loss: 0.0116\n",
      "Epoch 174/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0055 - val_loss: 0.0182\n",
      "Epoch 175/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0076 - val_loss: 0.0375\n",
      "Epoch 176/1000\n",
      "3552/3552 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0300\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00176: early stopping\n",
      "(423, 2)\n",
      "(423, 2)\n",
      "(3946, 16, 1)\n",
      "(3946, 3)\n",
      "Train on 3551 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3551/3551 [==============================] - 3s 871us/step - loss: 3.6435 - val_loss: 0.0784\n",
      "Epoch 2/1000\n",
      "3551/3551 [==============================] - 3s 760us/step - loss: 0.1909 - val_loss: 0.0347\n",
      "Epoch 3/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0894 - val_loss: 0.0395\n",
      "Epoch 4/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0552 - val_loss: 0.0075\n",
      "Epoch 5/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0416 - val_loss: 0.0107\n",
      "Epoch 6/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0325 - val_loss: 0.0127\n",
      "Epoch 7/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0273 - val_loss: 0.0133\n",
      "Epoch 8/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0230 - val_loss: 0.0104\n",
      "Epoch 9/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0213 - val_loss: 0.0114\n",
      "Epoch 10/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0190 - val_loss: 0.0155\n",
      "Epoch 11/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0180 - val_loss: 0.0097\n",
      "Epoch 12/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0159 - val_loss: 0.0131\n",
      "Epoch 13/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 14/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0147 - val_loss: 0.0218\n",
      "Epoch 15/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0147 - val_loss: 0.0068\n",
      "Epoch 16/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0149 - val_loss: 0.0112\n",
      "Epoch 17/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0156 - val_loss: 0.0119\n",
      "Epoch 18/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0130 - val_loss: 0.0144\n",
      "Epoch 19/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 20/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 21/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0117 - val_loss: 0.0090\n",
      "Epoch 22/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0140 - val_loss: 0.0104\n",
      "Epoch 23/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0131 - val_loss: 0.0144\n",
      "Epoch 24/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 25/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0131 - val_loss: 0.0202\n",
      "Epoch 26/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0133 - val_loss: 0.0145\n",
      "Epoch 27/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0116 - val_loss: 0.0185\n",
      "Epoch 28/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 29/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0129 - val_loss: 0.0090\n",
      "Epoch 30/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0120 - val_loss: 0.0278\n",
      "Epoch 31/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0111 - val_loss: 0.0068\n",
      "Epoch 32/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0138 - val_loss: 0.0271\n",
      "Epoch 33/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0313\n",
      "Epoch 34/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 35/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0102 - val_loss: 0.0141\n",
      "Epoch 36/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0111 - val_loss: 0.0359\n",
      "Epoch 37/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0112 - val_loss: 0.0356\n",
      "Epoch 38/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0104 - val_loss: 0.0213\n",
      "Epoch 39/1000\n",
      "3551/3551 [==============================] - 3s 850us/step - loss: 0.0136 - val_loss: 0.0231\n",
      "Epoch 40/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0101 - val_loss: 0.0201\n",
      "Epoch 41/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0102 - val_loss: 0.0487\n",
      "Epoch 42/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0125 - val_loss: 0.0189\n",
      "Epoch 43/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0115 - val_loss: 0.0464\n",
      "Epoch 44/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0106 - val_loss: 0.0405\n",
      "Epoch 45/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0124 - val_loss: 0.0176\n",
      "Epoch 46/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0097 - val_loss: 0.0546\n",
      "Epoch 47/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0100 - val_loss: 0.0211\n",
      "Epoch 48/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0106 - val_loss: 0.0405\n",
      "Epoch 49/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0152 - val_loss: 0.0421\n",
      "Epoch 50/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0153 - val_loss: 0.0116\n",
      "Epoch 51/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0108 - val_loss: 0.0592\n",
      "Epoch 52/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0130 - val_loss: 0.0476\n",
      "Epoch 53/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0136 - val_loss: 0.0437\n",
      "Epoch 54/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0095 - val_loss: 0.0545\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0093 - val_loss: 0.0595\n",
      "Epoch 56/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0088 - val_loss: 0.0251\n",
      "Epoch 57/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0100 - val_loss: 0.0454\n",
      "Epoch 58/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0116 - val_loss: 0.0625\n",
      "Epoch 59/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0105 - val_loss: 0.0785\n",
      "Epoch 60/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0104 - val_loss: 0.0285\n",
      "Epoch 61/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0100 - val_loss: 0.0523\n",
      "Epoch 62/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0095 - val_loss: 0.0362\n",
      "Epoch 63/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0094 - val_loss: 0.0298\n",
      "Epoch 64/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0077 - val_loss: 0.0129\n",
      "Epoch 65/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0075 - val_loss: 0.0198\n",
      "Epoch 66/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0073 - val_loss: 0.0194\n",
      "Epoch 67/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0077 - val_loss: 0.0176\n",
      "Epoch 68/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0073 - val_loss: 0.0191\n",
      "Epoch 69/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0074 - val_loss: 0.0190\n",
      "Epoch 70/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0073 - val_loss: 0.0175\n",
      "Epoch 71/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0079 - val_loss: 0.0392\n",
      "Epoch 72/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0093 - val_loss: 0.0516\n",
      "Epoch 73/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0099 - val_loss: 0.0435\n",
      "Epoch 74/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0154\n",
      "Epoch 75/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0085 - val_loss: 0.0266\n",
      "Epoch 76/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0084 - val_loss: 0.0364\n",
      "Epoch 77/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0088 - val_loss: 0.0329\n",
      "Epoch 78/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0091 - val_loss: 0.0102\n",
      "Epoch 79/1000\n",
      "3551/3551 [==============================] - 3s 787us/step - loss: 0.0096 - val_loss: 0.0270\n",
      "Epoch 80/1000\n",
      "3551/3551 [==============================] - 3s 769us/step - loss: 0.0083 - val_loss: 0.0301\n",
      "Epoch 81/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0093 - val_loss: 0.0255\n",
      "Epoch 82/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0087 - val_loss: 0.0162\n",
      "Epoch 83/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0091 - val_loss: 0.0195\n",
      "Epoch 84/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 85/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0081 - val_loss: 0.0311\n",
      "Epoch 86/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 87/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0078 - val_loss: 0.0123\n",
      "Epoch 88/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0080 - val_loss: 0.0213\n",
      "Epoch 89/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0129\n",
      "Epoch 90/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0070 - val_loss: 0.0149\n",
      "Epoch 91/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0073 - val_loss: 0.0116\n",
      "Epoch 92/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 93/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0081 - val_loss: 0.0263\n",
      "Epoch 94/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0078 - val_loss: 0.0175\n",
      "Epoch 95/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0075 - val_loss: 0.0144\n",
      "Epoch 96/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0123\n",
      "Epoch 97/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0071 - val_loss: 0.0122\n",
      "Epoch 98/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 99/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 100/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 101/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0099\n",
      "Epoch 102/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0160\n",
      "Epoch 103/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0084 - val_loss: 0.0236\n",
      "Epoch 104/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0077 - val_loss: 0.0204\n",
      "Epoch 105/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0090 - val_loss: 0.0153\n",
      "Epoch 106/1000\n",
      "3551/3551 [==============================] - 3s 979us/step - loss: 0.0087 - val_loss: 0.0460\n",
      "Epoch 107/1000\n",
      "3551/3551 [==============================] - 2s 700us/step - loss: 0.0091 - val_loss: 0.0200\n",
      "Epoch 108/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0068 - val_loss: 0.0110\n",
      "Epoch 109/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 110/1000\n",
      "3551/3551 [==============================] - 3s 889us/step - loss: 0.0069 - val_loss: 0.0089\n",
      "Epoch 111/1000\n",
      "3551/3551 [==============================] - 3s 884us/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 112/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 113/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 114/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0223\n",
      "Epoch 115/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0090\n",
      "Epoch 116/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0103\n",
      "Epoch 117/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0104\n",
      "Epoch 118/1000\n",
      "3551/3551 [==============================] - 3s 734us/step - loss: 0.0071 - val_loss: 0.0139\n",
      "Epoch 119/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0073 - val_loss: 0.0129\n",
      "Epoch 120/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0076 - val_loss: 0.0231\n",
      "Epoch 121/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0074 - val_loss: 0.0387\n",
      "Epoch 122/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0086 - val_loss: 0.0268\n",
      "Epoch 123/1000\n",
      "3551/3551 [==============================] - 4s 986us/step - loss: 0.0075 - val_loss: 0.0210\n",
      "Epoch 124/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0072 - val_loss: 0.0165\n",
      "Epoch 125/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 126/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 127/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 128/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0088\n",
      "Epoch 129/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0072 - val_loss: 0.0072\n",
      "Epoch 130/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 131/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0091\n",
      "Epoch 132/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 133/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0108\n",
      "Epoch 134/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0122\n",
      "Epoch 135/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0092 - val_loss: 0.0223\n",
      "Epoch 136/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0296 - val_loss: 0.0184\n",
      "Epoch 137/1000\n",
      "3551/3551 [==============================] - 3s 717us/step - loss: 0.0119 - val_loss: 0.0253\n",
      "Epoch 138/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0092 - val_loss: 0.0446\n",
      "Epoch 139/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0100 - val_loss: 0.0186\n",
      "Epoch 140/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0181\n",
      "Epoch 141/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 142/1000\n",
      "3551/3551 [==============================] - 3s 868us/step - loss: 0.0070 - val_loss: 0.0116\n",
      "Epoch 143/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0067 - val_loss: 0.0138\n",
      "Epoch 144/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0070 - val_loss: 0.0160\n",
      "Epoch 145/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0233\n",
      "Epoch 146/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0069 - val_loss: 0.0224\n",
      "Epoch 147/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0167\n",
      "Epoch 148/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0184\n",
      "Epoch 149/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0070 - val_loss: 0.0089\n",
      "Epoch 150/1000\n",
      "3551/3551 [==============================] - 3s 710us/step - loss: 0.0072 - val_loss: 0.0147\n",
      "Epoch 151/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0212\n",
      "Epoch 152/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0208\n",
      "Epoch 153/1000\n",
      "3551/3551 [==============================] - 4s 989us/step - loss: 0.0074 - val_loss: 0.0237\n",
      "Epoch 154/1000\n",
      "3551/3551 [==============================] - 3s 726us/step - loss: 0.0072 - val_loss: 0.0254\n",
      "Epoch 155/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0081 - val_loss: 0.0280\n",
      "Epoch 156/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0162\n",
      "Epoch 157/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0153\n",
      "Epoch 158/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0064 - val_loss: 0.0143\n",
      "Epoch 159/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0069 - val_loss: 0.0167\n",
      "Epoch 160/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0069 - val_loss: 0.0096\n",
      "Epoch 161/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 162/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0083 - val_loss: 0.0233\n",
      "Epoch 163/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0080 - val_loss: 0.0098\n",
      "Epoch 164/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0071 - val_loss: 0.0103\n",
      "Epoch 165/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0060 - val_loss: 0.0098\n",
      "Epoch 166/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 167/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0072 - val_loss: 0.0088\n",
      "Epoch 168/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0069 - val_loss: 0.0083\n",
      "Epoch 169/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0076 - val_loss: 0.0137\n",
      "Epoch 170/1000\n",
      "3551/3551 [==============================] - 3s 754us/step - loss: 0.0074 - val_loss: 0.0224\n",
      "Epoch 171/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0071 - val_loss: 0.0093\n",
      "Epoch 172/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0076 - val_loss: 0.0175\n",
      "Epoch 173/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 174/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0149\n",
      "Epoch 175/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0102\n",
      "Epoch 176/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0101\n",
      "Epoch 177/1000\n",
      "3551/3551 [==============================] - 3s 974us/step - loss: 0.0072 - val_loss: 0.0110\n",
      "Epoch 178/1000\n",
      "3551/3551 [==============================] - 3s 909us/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 179/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0074\n",
      "Epoch 180/1000\n",
      "3551/3551 [==============================] - 3s 980us/step - loss: 0.0066 - val_loss: 0.0083\n",
      "Epoch 181/1000\n",
      "3551/3551 [==============================] - 3s 860us/step - loss: 0.0072 - val_loss: 0.0086\n",
      "Epoch 182/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0084\n",
      "Epoch 183/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0166\n",
      "Epoch 184/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0080\n",
      "Epoch 185/1000\n",
      "3551/3551 [==============================] - 3s 772us/step - loss: 0.0069 - val_loss: 0.0089\n",
      "Epoch 186/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0095\n",
      "Epoch 187/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 188/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0078 - val_loss: 0.0132\n",
      "Epoch 189/1000\n",
      "3551/3551 [==============================] - 2s 704us/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 190/1000\n",
      "3551/3551 [==============================] - 3s 709us/step - loss: 0.0079 - val_loss: 0.0190\n",
      "Epoch 191/1000\n",
      "3551/3551 [==============================] - 3s 851us/step - loss: 0.0076 - val_loss: 0.0195\n",
      "Epoch 192/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0170\n",
      "Epoch 193/1000\n",
      "3551/3551 [==============================] - 4s 986us/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 194/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 195/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 196/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0072 - val_loss: 0.0099\n",
      "Epoch 197/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0063\n",
      "Epoch 198/1000\n",
      "3551/3551 [==============================] - 3s 742us/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 199/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 200/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 201/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0064 - val_loss: 0.0081\n",
      "Epoch 202/1000\n",
      "3551/3551 [==============================] - 3s 725us/step - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 203/1000\n",
      "3551/3551 [==============================] - 3s 857us/step - loss: 0.0062 - val_loss: 0.0077\n",
      "Epoch 204/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 205/1000\n",
      "3551/3551 [==============================] - 6s 2ms/step - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 206/1000\n",
      "3551/3551 [==============================] - 3s 968us/step - loss: 0.0070 - val_loss: 0.0117\n",
      "Epoch 207/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 208/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 209/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 210/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 211/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0133\n",
      "Epoch 212/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Epoch 213/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0068 - val_loss: 0.0107\n",
      "Epoch 214/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0078\n",
      "Epoch 215/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 216/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0095\n",
      "Epoch 217/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0085\n",
      "Epoch 218/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0068 - val_loss: 0.0084\n",
      "Epoch 219/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0117\n",
      "Epoch 220/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0100\n",
      "Epoch 221/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0202\n",
      "Epoch 222/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 223/1000\n",
      "3551/3551 [==============================] - 3s 728us/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 224/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0089\n",
      "Epoch 225/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 226/1000\n",
      "3551/3551 [==============================] - 3s 932us/step - loss: 0.0065 - val_loss: 0.0097\n",
      "Epoch 227/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 228/1000\n",
      "3551/3551 [==============================] - 3s 847us/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 229/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 230/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 231/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0064 - val_loss: 0.0095\n",
      "Epoch 232/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 233/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0094\n",
      "Epoch 234/1000\n",
      "3551/3551 [==============================] - 3s 791us/step - loss: 0.0066 - val_loss: 0.0093\n",
      "Epoch 235/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0153\n",
      "Epoch 236/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0167\n",
      "Epoch 237/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0103\n",
      "Epoch 238/1000\n",
      "3551/3551 [==============================] - 3s 937us/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 239/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0071 - val_loss: 0.0131\n",
      "Epoch 240/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0083\n",
      "Epoch 241/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0071 - val_loss: 0.0282\n",
      "Epoch 242/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0090\n",
      "Epoch 243/1000\n",
      "3551/3551 [==============================] - 2s 683us/step - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 244/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0062 - val_loss: 0.0144\n",
      "Epoch 245/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0073 - val_loss: 0.0167\n",
      "Epoch 246/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0070 - val_loss: 0.0139\n",
      "Epoch 247/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 248/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 249/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0096\n",
      "Epoch 250/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 251/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0071\n",
      "Epoch 252/1000\n",
      "3551/3551 [==============================] - 3s 788us/step - loss: 0.0066 - val_loss: 0.0079\n",
      "Epoch 253/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0101\n",
      "Epoch 254/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 255/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0066 - val_loss: 0.0073\n",
      "Epoch 256/1000\n",
      "3551/3551 [==============================] - 3s 838us/step - loss: 0.0070 - val_loss: 0.0117\n",
      "Epoch 257/1000\n",
      "3551/3551 [==============================] - 3s 783us/step - loss: 0.0063 - val_loss: 0.0093\n",
      "Epoch 258/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 259/1000\n",
      "3551/3551 [==============================] - 3s 883us/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 260/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0069 - val_loss: 0.0082\n",
      "Epoch 261/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 262/1000\n",
      "3551/3551 [==============================] - 3s 883us/step - loss: 0.0075 - val_loss: 0.0080\n",
      "Epoch 263/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0080 - val_loss: 0.0112\n",
      "Epoch 264/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0072 - val_loss: 0.0100\n",
      "Epoch 265/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 266/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0061 - val_loss: 0.0099\n",
      "Epoch 267/1000\n",
      "3551/3551 [==============================] - 3s 815us/step - loss: 0.0063 - val_loss: 0.0070\n",
      "Epoch 268/1000\n",
      "3551/3551 [==============================] - 3s 724us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 269/1000\n",
      "3551/3551 [==============================] - 3s 932us/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Epoch 270/1000\n",
      "3551/3551 [==============================] - 3s 930us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "Epoch 271/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 272/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0080\n",
      "Epoch 273/1000\n",
      "3551/3551 [==============================] - 3s 827us/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 274/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0065 - val_loss: 0.0106\n",
      "Epoch 275/1000\n",
      "3551/3551 [==============================] - 3s 722us/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 276/1000\n",
      "3551/3551 [==============================] - 2s 700us/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 277/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 278/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0059\n",
      "Epoch 279/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0061\n",
      "Epoch 280/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0120\n",
      "Epoch 281/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 282/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 283/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 284/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 285/1000\n",
      "3551/3551 [==============================] - 3s 804us/step - loss: 0.0064 - val_loss: 0.0067\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 287/1000\n",
      "3551/3551 [==============================] - 3s 760us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 288/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 289/1000\n",
      "3551/3551 [==============================] - 3s 796us/step - loss: 0.0064 - val_loss: 0.0128\n",
      "Epoch 290/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0061 - val_loss: 0.0108\n",
      "Epoch 291/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0066\n",
      "Epoch 292/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0180\n",
      "Epoch 293/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0063 - val_loss: 0.0137\n",
      "Epoch 294/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0060\n",
      "Epoch 295/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0067 - val_loss: 0.0099\n",
      "Epoch 296/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0113\n",
      "Epoch 297/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 298/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 299/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0060 - val_loss: 0.0096\n",
      "Epoch 300/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0062 - val_loss: 0.0082\n",
      "Epoch 301/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0063 - val_loss: 0.0090\n",
      "Epoch 302/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0100\n",
      "Epoch 303/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 304/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 305/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0062 - val_loss: 0.0067\n",
      "Epoch 306/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0075\n",
      "Epoch 307/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0064 - val_loss: 0.0107\n",
      "Epoch 308/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0091\n",
      "Epoch 309/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0090\n",
      "Epoch 310/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0134\n",
      "Epoch 311/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 312/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0065 - val_loss: 0.0071\n",
      "Epoch 313/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 314/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 315/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0063 - val_loss: 0.0122\n",
      "Epoch 316/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 317/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 318/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 319/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 320/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 321/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 322/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0068\n",
      "Epoch 323/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 324/1000\n",
      "3551/3551 [==============================] - 3s 893us/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 325/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 326/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0066 - val_loss: 0.0229\n",
      "Epoch 327/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0111\n",
      "Epoch 328/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0083\n",
      "Epoch 329/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0060 - val_loss: 0.0074\n",
      "Epoch 330/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0061 - val_loss: 0.0102\n",
      "Epoch 331/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0068 - val_loss: 0.0132\n",
      "Epoch 332/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0085 - val_loss: 0.0099\n",
      "Epoch 333/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0078 - val_loss: 0.0221\n",
      "Epoch 334/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0071 - val_loss: 0.0082\n",
      "Epoch 335/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 336/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0057 - val_loss: 0.0061\n",
      "Epoch 337/1000\n",
      "3551/3551 [==============================] - 3s 953us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 338/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 339/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 340/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 341/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 342/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Epoch 343/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0057 - val_loss: 0.0062\n",
      "Epoch 344/1000\n",
      "3551/3551 [==============================] - 3s 967us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 345/1000\n",
      "3551/3551 [==============================] - 3s 985us/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 346/1000\n",
      "3551/3551 [==============================] - 3s 903us/step - loss: 0.0056 - val_loss: 0.0063\n",
      "Epoch 347/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 348/1000\n",
      "3551/3551 [==============================] - 3s 741us/step - loss: 0.0059 - val_loss: 0.0060\n",
      "Epoch 349/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0063 - val_loss: 0.0139\n",
      "Epoch 350/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0059 - val_loss: 0.0061\n",
      "Epoch 351/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0058 - val_loss: 0.0059\n",
      "Epoch 352/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0064 - val_loss: 0.0064\n",
      "Epoch 353/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0067 - val_loss: 0.0130\n",
      "Epoch 354/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0061 - val_loss: 0.0094\n",
      "Epoch 355/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 356/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 357/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 358/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0062 - val_loss: 0.0061\n",
      "Epoch 359/1000\n",
      "3551/3551 [==============================] - 3s 858us/step - loss: 0.0067 - val_loss: 0.0136\n",
      "Epoch 360/1000\n",
      "3551/3551 [==============================] - 3s 726us/step - loss: 0.0058 - val_loss: 0.0074\n",
      "Epoch 361/1000\n",
      "3551/3551 [==============================] - 2s 675us/step - loss: 0.0059 - val_loss: 0.0066\n",
      "Epoch 362/1000\n",
      "3551/3551 [==============================] - 5s 1ms/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 363/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0058 - val_loss: 0.0062\n",
      "Epoch 364/1000\n",
      "3551/3551 [==============================] - 5s 2ms/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 365/1000\n",
      "3551/3551 [==============================] - 4s 1ms/step - loss: 0.0057 - val_loss: 0.0084\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00365: early stopping\n",
      "(422, 3)\n",
      "(422, 3)\n",
      "(3944, 16, 1)\n",
      "(3944, 5)\n",
      "Train on 3549 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 6.7220 - val_loss: 0.1682\n",
      "Epoch 2/1000\n",
      "3549/3549 [==============================] - 3s 784us/step - loss: 0.2670 - val_loss: 0.0565\n",
      "Epoch 3/1000\n",
      "3549/3549 [==============================] - 2s 702us/step - loss: 0.1225 - val_loss: 0.0411\n",
      "Epoch 4/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0893 - val_loss: 0.0355\n",
      "Epoch 5/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0607 - val_loss: 0.0191\n",
      "Epoch 6/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0457 - val_loss: 0.0230\n",
      "Epoch 7/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0376 - val_loss: 0.0214\n",
      "Epoch 8/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0328 - val_loss: 0.0192\n",
      "Epoch 9/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0281 - val_loss: 0.0154\n",
      "Epoch 10/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0268 - val_loss: 0.0150\n",
      "Epoch 11/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0237 - val_loss: 0.0189\n",
      "Epoch 12/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0226 - val_loss: 0.0279\n",
      "Epoch 13/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0206 - val_loss: 0.0234\n",
      "Epoch 14/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 15/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0197 - val_loss: 0.0148\n",
      "Epoch 16/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0189 - val_loss: 0.0132\n",
      "Epoch 17/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0192 - val_loss: 0.0098\n",
      "Epoch 18/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0189 - val_loss: 0.0102\n",
      "Epoch 19/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0188 - val_loss: 0.0100\n",
      "Epoch 20/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0186 - val_loss: 0.0140\n",
      "Epoch 21/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0177 - val_loss: 0.0164\n",
      "Epoch 22/1000\n",
      "3549/3549 [==============================] - 3s 932us/step - loss: 0.0163 - val_loss: 0.0108\n",
      "Epoch 23/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0160 - val_loss: 0.0123\n",
      "Epoch 24/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0148 - val_loss: 0.0141\n",
      "Epoch 25/1000\n",
      "3549/3549 [==============================] - 3s 773us/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 26/1000\n",
      "3549/3549 [==============================] - 3s 727us/step - loss: 0.0177 - val_loss: 0.0119\n",
      "Epoch 27/1000\n",
      "3549/3549 [==============================] - 2s 694us/step - loss: 0.0170 - val_loss: 0.0125\n",
      "Epoch 28/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0172 - val_loss: 0.0193\n",
      "Epoch 29/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0158 - val_loss: 0.0170\n",
      "Epoch 30/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0172 - val_loss: 0.0204\n",
      "Epoch 31/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0164 - val_loss: 0.0226\n",
      "Epoch 32/1000\n",
      "3549/3549 [==============================] - 3s 874us/step - loss: 0.0146 - val_loss: 0.0180\n",
      "Epoch 33/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0159 - val_loss: 0.0164\n",
      "Epoch 34/1000\n",
      "3549/3549 [==============================] - 3s 858us/step - loss: 0.0173 - val_loss: 0.0192\n",
      "Epoch 35/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0172 - val_loss: 0.0159\n",
      "Epoch 36/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0175 - val_loss: 0.0231\n",
      "Epoch 37/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0185 - val_loss: 0.0334\n",
      "Epoch 38/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0163 - val_loss: 0.0294\n",
      "Epoch 39/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0163 - val_loss: 0.0386\n",
      "Epoch 40/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0160 - val_loss: 0.0323\n",
      "Epoch 41/1000\n",
      "3549/3549 [==============================] - 3s 889us/step - loss: 0.0170 - val_loss: 0.0307\n",
      "Epoch 42/1000\n",
      "3549/3549 [==============================] - 3s 730us/step - loss: 0.0187 - val_loss: 0.0457\n",
      "Epoch 43/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0176 - val_loss: 0.0189\n",
      "Epoch 44/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0171 - val_loss: 0.0370\n",
      "Epoch 45/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0178 - val_loss: 0.0381\n",
      "Epoch 46/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0151 - val_loss: 0.0259\n",
      "Epoch 47/1000\n",
      "3549/3549 [==============================] - 3s 932us/step - loss: 0.0159 - val_loss: 0.0379\n",
      "Epoch 48/1000\n",
      "3549/3549 [==============================] - 3s 737us/step - loss: 0.0162 - val_loss: 0.0316\n",
      "Epoch 49/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0164 - val_loss: 0.0211\n",
      "Epoch 50/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0165 - val_loss: 0.0363\n",
      "Epoch 51/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0176 - val_loss: 0.0469\n",
      "Epoch 52/1000\n",
      "3549/3549 [==============================] - 3s 834us/step - loss: 0.0170 - val_loss: 0.0323\n",
      "Epoch 53/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0189 - val_loss: 0.0348\n",
      "Epoch 54/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0157 - val_loss: 0.0215\n",
      "Epoch 55/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0158 - val_loss: 0.0147\n",
      "Epoch 56/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0154 - val_loss: 0.0140\n",
      "Epoch 57/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0197 - val_loss: 0.0571\n",
      "Epoch 58/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0151 - val_loss: 0.0318\n",
      "Epoch 59/1000\n",
      "3549/3549 [==============================] - 3s 833us/step - loss: 0.0154 - val_loss: 0.0183\n",
      "Epoch 60/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0138 - val_loss: 0.0343\n",
      "Epoch 61/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0136 - val_loss: 0.0161\n",
      "Epoch 62/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0156 - val_loss: 0.0254\n",
      "Epoch 63/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0145 - val_loss: 0.0221\n",
      "Epoch 64/1000\n",
      "3549/3549 [==============================] - 3s 759us/step - loss: 0.0144 - val_loss: 0.0170\n",
      "Epoch 65/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0169 - val_loss: 0.0328\n",
      "Epoch 66/1000\n",
      "3549/3549 [==============================] - 4s 989us/step - loss: 0.0144 - val_loss: 0.0145\n",
      "Epoch 67/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0162 - val_loss: 0.0338\n",
      "Epoch 68/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0142 - val_loss: 0.0323\n",
      "Epoch 69/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0130 - val_loss: 0.0129\n",
      "Epoch 70/1000\n",
      "3549/3549 [==============================] - 3s 921us/step - loss: 0.0146 - val_loss: 0.0250\n",
      "Epoch 71/1000\n",
      "3549/3549 [==============================] - 4s 995us/step - loss: 0.0128 - val_loss: 0.0233\n",
      "Epoch 72/1000\n",
      "3549/3549 [==============================] - 2s 689us/step - loss: 0.0139 - val_loss: 0.0217\n",
      "Epoch 73/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0128 - val_loss: 0.0103\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0135 - val_loss: 0.0247\n",
      "Epoch 75/1000\n",
      "3549/3549 [==============================] - 6s 2ms/step - loss: 0.0123 - val_loss: 0.0186\n",
      "Epoch 76/1000\n",
      "3549/3549 [==============================] - 5s 2ms/step - loss: 0.0119 - val_loss: 0.0151\n",
      "Epoch 77/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 78/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0123 - val_loss: 0.0187\n",
      "Epoch 79/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0121 - val_loss: 0.0250\n",
      "Epoch 80/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 81/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0121 - val_loss: 0.0236\n",
      "Epoch 82/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0119 - val_loss: 0.0171\n",
      "Epoch 83/1000\n",
      "3549/3549 [==============================] - 3s 784us/step - loss: 0.0119 - val_loss: 0.0177\n",
      "Epoch 84/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0114 - val_loss: 0.0184\n",
      "Epoch 85/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0115 - val_loss: 0.0160\n",
      "Epoch 86/1000\n",
      "3549/3549 [==============================] - 3s 978us/step - loss: 0.0117 - val_loss: 0.0200\n",
      "Epoch 87/1000\n",
      "3549/3549 [==============================] - 3s 749us/step - loss: 0.0114 - val_loss: 0.0149\n",
      "Epoch 88/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0116 - val_loss: 0.0220\n",
      "Epoch 89/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0122 - val_loss: 0.0150\n",
      "Epoch 90/1000\n",
      "3549/3549 [==============================] - 6s 2ms/step - loss: 0.0118 - val_loss: 0.0271\n",
      "Epoch 91/1000\n",
      "3549/3549 [==============================] - 3s 882us/step - loss: 0.0127 - val_loss: 0.0288\n",
      "Epoch 92/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0120 - val_loss: 0.0211\n",
      "Epoch 93/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0121 - val_loss: 0.0101\n",
      "Epoch 94/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0123 - val_loss: 0.0436\n",
      "Epoch 95/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0125 - val_loss: 0.0260\n",
      "Epoch 96/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0126 - val_loss: 0.0507\n",
      "Epoch 97/1000\n",
      "3549/3549 [==============================] - 3s 791us/step - loss: 0.0120 - val_loss: 0.0188\n",
      "Epoch 98/1000\n",
      "3549/3549 [==============================] - 3s 771us/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 99/1000\n",
      "3549/3549 [==============================] - 3s 936us/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 100/1000\n",
      "3549/3549 [==============================] - 3s 831us/step - loss: 0.0105 - val_loss: 0.0201\n",
      "Epoch 101/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 102/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 103/1000\n",
      "3549/3549 [==============================] - 3s 964us/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 104/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0107 - val_loss: 0.0145\n",
      "Epoch 105/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0110 - val_loss: 0.0210\n",
      "Epoch 106/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0111 - val_loss: 0.0146\n",
      "Epoch 107/1000\n",
      "3549/3549 [==============================] - 3s 875us/step - loss: 0.0103 - val_loss: 0.0150\n",
      "Epoch 108/1000\n",
      "3549/3549 [==============================] - 3s 961us/step - loss: 0.0105 - val_loss: 0.0150\n",
      "Epoch 109/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0118 - val_loss: 0.0257\n",
      "Epoch 110/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0158 - val_loss: 0.0257\n",
      "Epoch 111/1000\n",
      "3549/3549 [==============================] - 3s 724us/step - loss: 0.0102 - val_loss: 0.0178\n",
      "Epoch 112/1000\n",
      "3549/3549 [==============================] - 2s 691us/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 113/1000\n",
      "3549/3549 [==============================] - 3s 859us/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 114/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 115/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 116/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0100 - val_loss: 0.0086\n",
      "Epoch 117/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0109 - val_loss: 0.0274\n",
      "Epoch 118/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 119/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 120/1000\n",
      "3549/3549 [==============================] - 6s 2ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 121/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0106 - val_loss: 0.0160\n",
      "Epoch 122/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0105 - val_loss: 0.0241\n",
      "Epoch 123/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 124/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0113 - val_loss: 0.0179\n",
      "Epoch 125/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0099 - val_loss: 0.0140\n",
      "Epoch 126/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0097 - val_loss: 0.0086\n",
      "Epoch 127/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0238\n",
      "Epoch 128/1000\n",
      "3549/3549 [==============================] - 3s 771us/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 129/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 130/1000\n",
      "3549/3549 [==============================] - 3s 927us/step - loss: 0.0114 - val_loss: 0.0232\n",
      "Epoch 131/1000\n",
      "3549/3549 [==============================] - 3s 874us/step - loss: 0.0111 - val_loss: 0.0415\n",
      "Epoch 132/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0104 - val_loss: 0.0221\n",
      "Epoch 133/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0107 - val_loss: 0.0127\n",
      "Epoch 134/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 135/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0106 - val_loss: 0.0153\n",
      "Epoch 136/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 137/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0110 - val_loss: 0.0166\n",
      "Epoch 138/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 139/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0105 - val_loss: 0.0162\n",
      "Epoch 140/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 141/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0109 - val_loss: 0.0165\n",
      "Epoch 142/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0103 - val_loss: 0.0255\n",
      "Epoch 143/1000\n",
      "3549/3549 [==============================] - 3s 956us/step - loss: 0.0102 - val_loss: 0.0218\n",
      "Epoch 144/1000\n",
      "3549/3549 [==============================] - 3s 796us/step - loss: 0.0119 - val_loss: 0.0257\n",
      "Epoch 145/1000\n",
      "3549/3549 [==============================] - 3s 895us/step - loss: 0.0107 - val_loss: 0.0088\n",
      "Epoch 146/1000\n",
      "3549/3549 [==============================] - 4s 1000us/step - loss: 0.0093 - val_loss: 0.0088\n",
      "Epoch 147/1000\n",
      "3549/3549 [==============================] - 3s 947us/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 148/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0100 - val_loss: 0.0179\n",
      "Epoch 149/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 150/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 151/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0103 - val_loss: 0.0262\n",
      "Epoch 152/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0094 - val_loss: 0.0150\n",
      "Epoch 153/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0101 - val_loss: 0.0173\n",
      "Epoch 154/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 155/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 156/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 157/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 158/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0113 - val_loss: 0.0202\n",
      "Epoch 159/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0097 - val_loss: 0.0190\n",
      "Epoch 160/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0094 - val_loss: 0.0108\n",
      "Epoch 161/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 162/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0098 - val_loss: 0.0123\n",
      "Epoch 163/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0105 - val_loss: 0.0205\n",
      "Epoch 164/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0104 - val_loss: 0.0175\n",
      "Epoch 165/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 166/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 167/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0099 - val_loss: 0.0258\n",
      "Epoch 168/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0107 - val_loss: 0.0234\n",
      "Epoch 169/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0103 - val_loss: 0.0173\n",
      "Epoch 170/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 171/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0097 - val_loss: 0.0226\n",
      "Epoch 172/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0097 - val_loss: 0.0142\n",
      "Epoch 173/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 174/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0094 - val_loss: 0.0092\n",
      "Epoch 175/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0097 - val_loss: 0.0156\n",
      "Epoch 176/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0097 - val_loss: 0.0187\n",
      "Epoch 177/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0098 - val_loss: 0.0149\n",
      "Epoch 178/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0102 - val_loss: 0.0167\n",
      "Epoch 179/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0095 - val_loss: 0.0304\n",
      "Epoch 180/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 181/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0097 - val_loss: 0.0100\n",
      "Epoch 182/1000\n",
      "3549/3549 [==============================] - 3s 720us/step - loss: 0.0102 - val_loss: 0.0141\n",
      "Epoch 183/1000\n",
      "3549/3549 [==============================] - 3s 896us/step - loss: 0.0092 - val_loss: 0.0133\n",
      "Epoch 184/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0093 - val_loss: 0.0087\n",
      "Epoch 185/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0101 - val_loss: 0.0090\n",
      "Epoch 186/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 187/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0104 - val_loss: 0.0161\n",
      "Epoch 188/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 189/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0104 - val_loss: 0.0098\n",
      "Epoch 190/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 191/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0100 - val_loss: 0.0157\n",
      "Epoch 192/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 193/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 194/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0096 - val_loss: 0.0095\n",
      "Epoch 195/1000\n",
      "3549/3549 [==============================] - 3s 800us/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 196/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0094 - val_loss: 0.0166\n",
      "Epoch 197/1000\n",
      "3549/3549 [==============================] - 6s 2ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 198/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 199/1000\n",
      "3549/3549 [==============================] - 3s 957us/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 200/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0098 - val_loss: 0.0152\n",
      "Epoch 201/1000\n",
      "3549/3549 [==============================] - 3s 777us/step - loss: 0.0094 - val_loss: 0.0113\n",
      "Epoch 202/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 203/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0096 - val_loss: 0.0150\n",
      "Epoch 204/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 205/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0094 - val_loss: 0.0105\n",
      "Epoch 206/1000\n",
      "3549/3549 [==============================] - 5s 2ms/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 207/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 208/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 209/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 210/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0093 - val_loss: 0.0134\n",
      "Epoch 211/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 212/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0093 - val_loss: 0.0108\n",
      "Epoch 213/1000\n",
      "3549/3549 [==============================] - 2s 696us/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 214/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 215/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 216/1000\n",
      "3549/3549 [==============================] - 4s 1ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 217/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 218/1000\n",
      "3549/3549 [==============================] - 5s 1ms/step - loss: 0.0092 - val_loss: 0.0114\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00218: early stopping\n",
      "(420, 5)\n",
      "(420, 5)\n",
      "(3942, 16, 1)\n",
      "(3942, 7)\n",
      "Train on 3547 samples, validate on 395 samples\n",
      "Epoch 1/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 4.4833 - val_loss: 0.1778\n",
      "Epoch 2/1000\n",
      "3547/3547 [==============================] - 2s 628us/step - loss: 0.2300 - val_loss: 0.0345\n",
      "Epoch 3/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0929 - val_loss: 0.0258\n",
      "Epoch 4/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0627 - val_loss: 0.0215\n",
      "Epoch 5/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0503 - val_loss: 0.0178\n",
      "Epoch 6/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0408 - val_loss: 0.0184\n",
      "Epoch 7/1000\n",
      "3547/3547 [==============================] - 3s 743us/step - loss: 0.0358 - val_loss: 0.0172\n",
      "Epoch 8/1000\n",
      "3547/3547 [==============================] - 3s 841us/step - loss: 0.0328 - val_loss: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0297 - val_loss: 0.0209\n",
      "Epoch 10/1000\n",
      "3547/3547 [==============================] - 3s 932us/step - loss: 0.0273 - val_loss: 0.0254\n",
      "Epoch 11/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0248 - val_loss: 0.0251\n",
      "Epoch 12/1000\n",
      "3547/3547 [==============================] - 3s 837us/step - loss: 0.0234 - val_loss: 0.0223\n",
      "Epoch 13/1000\n",
      "3547/3547 [==============================] - 3s 952us/step - loss: 0.0228 - val_loss: 0.0159\n",
      "Epoch 14/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0215 - val_loss: 0.0223\n",
      "Epoch 15/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0215 - val_loss: 0.0226\n",
      "Epoch 16/1000\n",
      "3547/3547 [==============================] - 3s 944us/step - loss: 0.0209 - val_loss: 0.0152\n",
      "Epoch 17/1000\n",
      "3547/3547 [==============================] - 3s 914us/step - loss: 0.0200 - val_loss: 0.0183\n",
      "Epoch 18/1000\n",
      "3547/3547 [==============================] - 3s 933us/step - loss: 0.0197 - val_loss: 0.0138\n",
      "Epoch 19/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0189 - val_loss: 0.0231\n",
      "Epoch 20/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0192 - val_loss: 0.0215\n",
      "Epoch 21/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0187 - val_loss: 0.0168\n",
      "Epoch 22/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0188 - val_loss: 0.0223\n",
      "Epoch 23/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0188 - val_loss: 0.0210\n",
      "Epoch 24/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0192 - val_loss: 0.0190\n",
      "Epoch 25/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0184 - val_loss: 0.0147\n",
      "Epoch 26/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 27/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0184 - val_loss: 0.0218\n",
      "Epoch 28/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0186 - val_loss: 0.0196\n",
      "Epoch 29/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0181 - val_loss: 0.0238\n",
      "Epoch 30/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0179 - val_loss: 0.0199\n",
      "Epoch 31/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0175 - val_loss: 0.0215\n",
      "Epoch 32/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0162 - val_loss: 0.0168\n",
      "Epoch 33/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0173 - val_loss: 0.0194\n",
      "Epoch 34/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0170 - val_loss: 0.0233\n",
      "Epoch 35/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0173 - val_loss: 0.0218\n",
      "Epoch 36/1000\n",
      "3547/3547 [==============================] - 3s 910us/step - loss: 0.0175 - val_loss: 0.0326\n",
      "Epoch 37/1000\n",
      "3547/3547 [==============================] - 3s 891us/step - loss: 0.0169 - val_loss: 0.0252\n",
      "Epoch 38/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0180 - val_loss: 0.0427\n",
      "Epoch 39/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0159 - val_loss: 0.0203\n",
      "Epoch 40/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0175 - val_loss: 0.0367\n",
      "Epoch 41/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0170 - val_loss: 0.0217\n",
      "Epoch 42/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0160 - val_loss: 0.0305\n",
      "Epoch 43/1000\n",
      "3547/3547 [==============================] - 3s 789us/step - loss: 0.0167 - val_loss: 0.0435\n",
      "Epoch 44/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0164 - val_loss: 0.0254\n",
      "Epoch 45/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0170 - val_loss: 0.0480\n",
      "Epoch 46/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0161 - val_loss: 0.0457\n",
      "Epoch 47/1000\n",
      "3547/3547 [==============================] - 3s 776us/step - loss: 0.0154 - val_loss: 0.0354\n",
      "Epoch 48/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0171 - val_loss: 0.0560\n",
      "Epoch 49/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0177 - val_loss: 0.0751\n",
      "Epoch 50/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0171 - val_loss: 0.0525\n",
      "Epoch 51/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0161 - val_loss: 0.0434\n",
      "Epoch 52/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0150 - val_loss: 0.0369\n",
      "Epoch 53/1000\n",
      "3547/3547 [==============================] - 3s 842us/step - loss: 0.0159 - val_loss: 0.0421\n",
      "Epoch 54/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0149 - val_loss: 0.0251\n",
      "Epoch 55/1000\n",
      "3547/3547 [==============================] - 3s 716us/step - loss: 0.0144 - val_loss: 0.0399\n",
      "Epoch 56/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0151 - val_loss: 0.0185\n",
      "Epoch 57/1000\n",
      "3547/3547 [==============================] - 3s 719us/step - loss: 0.0143 - val_loss: 0.0343\n",
      "Epoch 58/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0150 - val_loss: 0.0293\n",
      "Epoch 59/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0158 - val_loss: 0.0489\n",
      "Epoch 60/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0150 - val_loss: 0.0312\n",
      "Epoch 61/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0150 - val_loss: 0.0323\n",
      "Epoch 62/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0152 - val_loss: 0.0571\n",
      "Epoch 63/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0164 - val_loss: 0.0467\n",
      "Epoch 64/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0156 - val_loss: 0.0282\n",
      "Epoch 65/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0136 - val_loss: 0.0176\n",
      "Epoch 66/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0140 - val_loss: 0.0220\n",
      "Epoch 67/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0139 - val_loss: 0.0190\n",
      "Epoch 68/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0140 - val_loss: 0.0215\n",
      "Epoch 69/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0146 - val_loss: 0.0297\n",
      "Epoch 70/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0142 - val_loss: 0.0216\n",
      "Epoch 71/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0141 - val_loss: 0.0285\n",
      "Epoch 72/1000\n",
      "3547/3547 [==============================] - 3s 933us/step - loss: 0.0141 - val_loss: 0.0193\n",
      "Epoch 73/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0132 - val_loss: 0.0365\n",
      "Epoch 74/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0151 - val_loss: 0.0326\n",
      "Epoch 75/1000\n",
      "3547/3547 [==============================] - 3s 956us/step - loss: 0.0144 - val_loss: 0.0156\n",
      "Epoch 76/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0147 - val_loss: 0.0551\n",
      "Epoch 77/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0140 - val_loss: 0.0279\n",
      "Epoch 78/1000\n",
      "3547/3547 [==============================] - 3s 836us/step - loss: 0.0134 - val_loss: 0.0175\n",
      "Epoch 79/1000\n",
      "3547/3547 [==============================] - 3s 825us/step - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 80/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0131 - val_loss: 0.0192\n",
      "Epoch 81/1000\n",
      "3547/3547 [==============================] - 3s 957us/step - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 82/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0136 - val_loss: 0.0187\n",
      "Epoch 83/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0138 - val_loss: 0.0311\n",
      "Epoch 84/1000\n",
      "3547/3547 [==============================] - 3s 901us/step - loss: 0.0132 - val_loss: 0.0177\n",
      "Epoch 85/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0130 - val_loss: 0.0191\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 87/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0141 - val_loss: 0.0259\n",
      "Epoch 88/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0131 - val_loss: 0.0274\n",
      "Epoch 89/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 90/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0132 - val_loss: 0.0335\n",
      "Epoch 91/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0131 - val_loss: 0.0244\n",
      "Epoch 92/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0143 - val_loss: 0.0265\n",
      "Epoch 93/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0168 - val_loss: 0.0831\n",
      "Epoch 94/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0155 - val_loss: 0.0398\n",
      "Epoch 95/1000\n",
      "3547/3547 [==============================] - 2s 682us/step - loss: 0.0142 - val_loss: 0.0291\n",
      "Epoch 96/1000\n",
      "3547/3547 [==============================] - 4s 1ms/step - loss: 0.0135 - val_loss: 0.0211\n",
      "Epoch 97/1000\n",
      "3547/3547 [==============================] - 5s 1ms/step - loss: 0.0133 - val_loss: 0.0169\n",
      "Epoch 98/1000\n",
      "3547/3547 [==============================] - 3s 951us/step - loss: 0.0130 - val_loss: 0.0140\n",
      "Epoch 99/1000\n",
      "3547/3547 [==============================] - 2s 677us/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 100/1000\n",
      "3547/3547 [==============================] - 2s 515us/step - loss: 0.0125 - val_loss: 0.0152\n",
      "Epoch 101/1000\n",
      "3547/3547 [==============================] - 2s 508us/step - loss: 0.0126 - val_loss: 0.0134\n",
      "Epoch 102/1000\n",
      "3547/3547 [==============================] - 2s 490us/step - loss: 0.0136 - val_loss: 0.0120\n",
      "Epoch 103/1000\n",
      "3547/3547 [==============================] - 2s 496us/step - loss: 0.0132 - val_loss: 0.0130\n",
      "Epoch 104/1000\n",
      "3547/3547 [==============================] - 2s 510us/step - loss: 0.0146 - val_loss: 0.0133\n",
      "Epoch 105/1000\n",
      "3547/3547 [==============================] - 2s 478us/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 106/1000\n",
      "3547/3547 [==============================] - 2s 494us/step - loss: 0.0143 - val_loss: 0.0120\n",
      "Epoch 107/1000\n",
      "3547/3547 [==============================] - 2s 611us/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 108/1000\n",
      "3547/3547 [==============================] - 2s 531us/step - loss: 0.0135 - val_loss: 0.0196\n",
      "Epoch 109/1000\n",
      "3547/3547 [==============================] - 2s 436us/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 110/1000\n",
      "3547/3547 [==============================] - 2s 450us/step - loss: 0.0137 - val_loss: 0.0165\n",
      "Epoch 111/1000\n",
      "3547/3547 [==============================] - 2s 425us/step - loss: 0.0125 - val_loss: 0.0196\n",
      "Epoch 112/1000\n",
      "3547/3547 [==============================] - 2s 433us/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 113/1000\n",
      "3547/3547 [==============================] - 2s 545us/step - loss: 0.0136 - val_loss: 0.0255\n",
      "Epoch 114/1000\n",
      "3547/3547 [==============================] - 2s 509us/step - loss: 0.0130 - val_loss: 0.0440\n",
      "Epoch 115/1000\n",
      "3547/3547 [==============================] - 2s 503us/step - loss: 0.0122 - val_loss: 0.0152\n",
      "Epoch 116/1000\n",
      "3547/3547 [==============================] - 2s 469us/step - loss: 0.0218 - val_loss: 0.0282\n",
      "Epoch 117/1000\n",
      "3547/3547 [==============================] - 1s 418us/step - loss: 0.0183 - val_loss: 0.0130\n",
      "Epoch 118/1000\n",
      "3547/3547 [==============================] - 2s 656us/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 119/1000\n",
      "3547/3547 [==============================] - 2s 599us/step - loss: 0.0131 - val_loss: 0.0148\n",
      "Epoch 120/1000\n",
      "3547/3547 [==============================] - 2s 550us/step - loss: 0.0131 - val_loss: 0.0142\n",
      "Epoch 121/1000\n",
      "3547/3547 [==============================] - 2s 583us/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 122/1000\n",
      "3547/3547 [==============================] - 2s 554us/step - loss: 0.0124 - val_loss: 0.0163\n",
      "Epoch 123/1000\n",
      "3547/3547 [==============================] - 2s 586us/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 124/1000\n",
      "3547/3547 [==============================] - 2s 601us/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 125/1000\n",
      "3547/3547 [==============================] - 2s 582us/step - loss: 0.0125 - val_loss: 0.0118\n",
      "Epoch 126/1000\n",
      "3547/3547 [==============================] - 2s 558us/step - loss: 0.0130 - val_loss: 0.0122\n",
      "Epoch 127/1000\n",
      "3547/3547 [==============================] - 2s 525us/step - loss: 0.0122 - val_loss: 0.0172\n",
      "Epoch 128/1000\n",
      "3547/3547 [==============================] - 2s 523us/step - loss: 0.0118 - val_loss: 0.0137\n",
      "Epoch 129/1000\n",
      "3547/3547 [==============================] - 2s 525us/step - loss: 0.0121 - val_loss: 0.0144\n",
      "Epoch 130/1000\n",
      "3547/3547 [==============================] - 2s 566us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 131/1000\n",
      "3547/3547 [==============================] - 2s 567us/step - loss: 0.0126 - val_loss: 0.0186\n",
      "Epoch 132/1000\n",
      "3547/3547 [==============================] - 2s 504us/step - loss: 0.0124 - val_loss: 0.0136\n",
      "Epoch 133/1000\n",
      "3547/3547 [==============================] - 2s 489us/step - loss: 0.0127 - val_loss: 0.0120\n",
      "Epoch 134/1000\n",
      "3547/3547 [==============================] - 2s 500us/step - loss: 0.0139 - val_loss: 0.0120\n",
      "Epoch 135/1000\n",
      "3547/3547 [==============================] - 2s 591us/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 136/1000\n",
      "3547/3547 [==============================] - 2s 568us/step - loss: 0.0127 - val_loss: 0.0197\n",
      "Epoch 137/1000\n",
      "3547/3547 [==============================] - 2s 560us/step - loss: 0.0195 - val_loss: 0.0524\n",
      "Epoch 138/1000\n",
      "3547/3547 [==============================] - 2s 557us/step - loss: 0.0150 - val_loss: 0.0144\n",
      "Epoch 139/1000\n",
      "3547/3547 [==============================] - 2s 586us/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 140/1000\n",
      "3547/3547 [==============================] - 2s 557us/step - loss: 0.0124 - val_loss: 0.0121\n",
      "Epoch 141/1000\n",
      "3547/3547 [==============================] - 2s 566us/step - loss: 0.0139 - val_loss: 0.0123\n",
      "Epoch 142/1000\n",
      "3547/3547 [==============================] - 2s 564us/step - loss: 0.0135 - val_loss: 0.0123\n",
      "Epoch 143/1000\n",
      "3547/3547 [==============================] - 2s 561us/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 144/1000\n",
      "3547/3547 [==============================] - 2s 624us/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 145/1000\n",
      "3547/3547 [==============================] - 2s 641us/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 146/1000\n",
      "3547/3547 [==============================] - 2s 639us/step - loss: 0.0125 - val_loss: 0.0120\n",
      "Epoch 147/1000\n",
      "3547/3547 [==============================] - 2s 646us/step - loss: 0.0120 - val_loss: 0.0117\n",
      "Epoch 148/1000\n",
      "3547/3547 [==============================] - 2s 630us/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 149/1000\n",
      "3547/3547 [==============================] - 2s 598us/step - loss: 0.0122 - val_loss: 0.0117\n",
      "Epoch 150/1000\n",
      "3547/3547 [==============================] - 2s 593us/step - loss: 0.0122 - val_loss: 0.0136\n",
      "Epoch 151/1000\n",
      "3547/3547 [==============================] - 2s 601us/step - loss: 0.0125 - val_loss: 0.0127\n",
      "Epoch 152/1000\n",
      "3547/3547 [==============================] - 2s 568us/step - loss: 0.0139 - val_loss: 0.0122\n",
      "Epoch 153/1000\n",
      "3547/3547 [==============================] - 2s 668us/step - loss: 0.0138 - val_loss: 0.0125\n",
      "Epoch 154/1000\n",
      "3547/3547 [==============================] - 2s 527us/step - loss: 0.0124 - val_loss: 0.0192\n",
      "Epoch 155/1000\n",
      "3547/3547 [==============================] - 2s 525us/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 156/1000\n",
      "3547/3547 [==============================] - 2s 524us/step - loss: 0.0123 - val_loss: 0.0123\n",
      "Epoch 157/1000\n",
      "3547/3547 [==============================] - 2s 545us/step - loss: 0.0129 - val_loss: 0.0119\n",
      "Epoch 158/1000\n",
      "3547/3547 [==============================] - 2s 597us/step - loss: 0.0135 - val_loss: 0.0255\n",
      "Epoch 159/1000\n",
      "3547/3547 [==============================] - 2s 559us/step - loss: 0.0130 - val_loss: 0.0257\n",
      "Epoch 160/1000\n",
      "3547/3547 [==============================] - 2s 560us/step - loss: 0.0129 - val_loss: 0.0127\n",
      "Epoch 161/1000\n",
      "3547/3547 [==============================] - 2s 548us/step - loss: 0.0134 - val_loss: 0.0148\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3547/3547 [==============================] - 2s 564us/step - loss: 0.0132 - val_loss: 0.0176\n",
      "Epoch 163/1000\n",
      "3547/3547 [==============================] - 2s 575us/step - loss: 0.0122 - val_loss: 0.0124\n",
      "Epoch 164/1000\n",
      "3547/3547 [==============================] - 2s 542us/step - loss: 0.0130 - val_loss: 0.0201\n",
      "Epoch 165/1000\n",
      "3547/3547 [==============================] - 2s 565us/step - loss: 0.0126 - val_loss: 0.0136\n",
      "Epoch 166/1000\n",
      "3547/3547 [==============================] - 2s 564us/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 167/1000\n",
      "3547/3547 [==============================] - 2s 558us/step - loss: 0.0122 - val_loss: 0.0121\n",
      "Epoch 168/1000\n",
      "3547/3547 [==============================] - 2s 535us/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 169/1000\n",
      "3547/3547 [==============================] - 2s 562us/step - loss: 0.0129 - val_loss: 0.0252\n",
      "Epoch 170/1000\n",
      "3547/3547 [==============================] - 2s 538us/step - loss: 0.0129 - val_loss: 0.0131\n",
      "Epoch 171/1000\n",
      "3547/3547 [==============================] - 2s 567us/step - loss: 0.0133 - val_loss: 0.0122\n",
      "Epoch 172/1000\n",
      "3547/3547 [==============================] - 2s 581us/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 173/1000\n",
      "3547/3547 [==============================] - 2s 563us/step - loss: 0.0127 - val_loss: 0.0146\n",
      "Epoch 174/1000\n",
      "3547/3547 [==============================] - 2s 552us/step - loss: 0.0122 - val_loss: 0.0138\n",
      "Epoch 175/1000\n",
      "3547/3547 [==============================] - 2s 540us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 176/1000\n",
      "3547/3547 [==============================] - 2s 555us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 177/1000\n",
      "3547/3547 [==============================] - 2s 541us/step - loss: 0.0137 - val_loss: 0.0138\n",
      "Epoch 178/1000\n",
      "3547/3547 [==============================] - 2s 570us/step - loss: 0.0141 - val_loss: 0.0150\n",
      "Epoch 179/1000\n",
      "3547/3547 [==============================] - 2s 578us/step - loss: 0.0128 - val_loss: 0.0132\n",
      "Epoch 180/1000\n",
      "3547/3547 [==============================] - 2s 550us/step - loss: 0.0127 - val_loss: 0.0125\n",
      "Epoch 181/1000\n",
      "3547/3547 [==============================] - 2s 570us/step - loss: 0.0133 - val_loss: 0.0129\n",
      "Epoch 182/1000\n",
      "3547/3547 [==============================] - 2s 525us/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 183/1000\n",
      "3547/3547 [==============================] - 2s 533us/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 184/1000\n",
      "3547/3547 [==============================] - 2s 531us/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 185/1000\n",
      "3547/3547 [==============================] - 2s 521us/step - loss: 0.0124 - val_loss: 0.0143\n",
      "Epoch 186/1000\n",
      "3547/3547 [==============================] - 2s 565us/step - loss: 0.0124 - val_loss: 0.0142\n",
      "Epoch 187/1000\n",
      "3547/3547 [==============================] - 2s 538us/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 188/1000\n",
      "3547/3547 [==============================] - 2s 579us/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 189/1000\n",
      "3547/3547 [==============================] - 2s 568us/step - loss: 0.0127 - val_loss: 0.0198\n",
      "Epoch 190/1000\n",
      "3547/3547 [==============================] - 2s 562us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 191/1000\n",
      "3547/3547 [==============================] - 2s 575us/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 192/1000\n",
      "3547/3547 [==============================] - 2s 553us/step - loss: 0.0129 - val_loss: 0.0125\n",
      "Epoch 193/1000\n",
      "3547/3547 [==============================] - 2s 560us/step - loss: 0.0122 - val_loss: 0.0144\n",
      "Epoch 194/1000\n",
      "3547/3547 [==============================] - 2s 545us/step - loss: 0.0117 - val_loss: 0.0168\n",
      "Epoch 195/1000\n",
      "3547/3547 [==============================] - 2s 575us/step - loss: 0.0127 - val_loss: 0.0123\n",
      "Epoch 196/1000\n",
      "3547/3547 [==============================] - 2s 550us/step - loss: 0.0126 - val_loss: 0.0137\n",
      "Epoch 197/1000\n",
      "3547/3547 [==============================] - 2s 550us/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 198/1000\n",
      "3547/3547 [==============================] - 2s 565us/step - loss: 0.0124 - val_loss: 0.0129\n",
      "Epoch 199/1000\n",
      "3547/3547 [==============================] - 2s 579us/step - loss: 0.0123 - val_loss: 0.0124\n",
      "Epoch 200/1000\n",
      "3547/3547 [==============================] - 2s 504us/step - loss: 0.0126 - val_loss: 0.0131\n",
      "Epoch 201/1000\n",
      "3547/3547 [==============================] - 2s 511us/step - loss: 0.0118 - val_loss: 0.0143\n",
      "Epoch 202/1000\n",
      "3547/3547 [==============================] - 2s 632us/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 203/1000\n",
      "3547/3547 [==============================] - 2s 556us/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 204/1000\n",
      "3547/3547 [==============================] - 2s 553us/step - loss: 0.0110 - val_loss: 0.0132\n",
      "Epoch 205/1000\n",
      "3547/3547 [==============================] - 2s 523us/step - loss: 0.0119 - val_loss: 0.0131\n",
      "Epoch 206/1000\n",
      "3547/3547 [==============================] - 2s 523us/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 207/1000\n",
      "3547/3547 [==============================] - 2s 526us/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 208/1000\n",
      "3547/3547 [==============================] - 2s 527us/step - loss: 0.0124 - val_loss: 0.0150\n",
      "Epoch 209/1000\n",
      "3547/3547 [==============================] - 2s 522us/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 210/1000\n",
      "3547/3547 [==============================] - 2s 552us/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 211/1000\n",
      "3547/3547 [==============================] - 2s 518us/step - loss: 0.0125 - val_loss: 0.0178\n",
      "Epoch 212/1000\n",
      "3547/3547 [==============================] - 2s 530us/step - loss: 0.0124 - val_loss: 0.0278\n",
      "Epoch 213/1000\n",
      "3547/3547 [==============================] - 2s 548us/step - loss: 0.0125 - val_loss: 0.0129\n",
      "Epoch 214/1000\n",
      "3547/3547 [==============================] - 2s 567us/step - loss: 0.0129 - val_loss: 0.0154\n",
      "Epoch 215/1000\n",
      "3547/3547 [==============================] - 2s 565us/step - loss: 0.0126 - val_loss: 0.0149\n",
      "Epoch 216/1000\n",
      "3547/3547 [==============================] - 2s 568us/step - loss: 0.0121 - val_loss: 0.0151\n",
      "Epoch 217/1000\n",
      "3547/3547 [==============================] - 2s 565us/step - loss: 0.0120 - val_loss: 0.0140\n",
      "Epoch 218/1000\n",
      "3547/3547 [==============================] - 2s 522us/step - loss: 0.0119 - val_loss: 0.0161\n",
      "Epoch 219/1000\n",
      "3547/3547 [==============================] - 2s 566us/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 220/1000\n",
      "3547/3547 [==============================] - 2s 562us/step - loss: 0.0118 - val_loss: 0.0136\n",
      "Epoch 221/1000\n",
      "3547/3547 [==============================] - 2s 566us/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 222/1000\n",
      "3547/3547 [==============================] - 2s 584us/step - loss: 0.0117 - val_loss: 0.0125\n",
      "Epoch 223/1000\n",
      "3547/3547 [==============================] - 2s 595us/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 224/1000\n",
      "3547/3547 [==============================] - 2s 530us/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 225/1000\n",
      "3547/3547 [==============================] - 2s 546us/step - loss: 0.0126 - val_loss: 0.0125\n",
      "Epoch 226/1000\n",
      "3547/3547 [==============================] - 2s 544us/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 227/1000\n",
      "3547/3547 [==============================] - 2s 532us/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 228/1000\n",
      "3547/3547 [==============================] - 2s 577us/step - loss: 0.0113 - val_loss: 0.0133\n",
      "Epoch 229/1000\n",
      "3547/3547 [==============================] - 2s 675us/step - loss: 0.0120 - val_loss: 0.0134\n",
      "Epoch 230/1000\n",
      "3547/3547 [==============================] - 3s 718us/step - loss: 0.0131 - val_loss: 0.0138\n",
      "Epoch 231/1000\n",
      "3547/3547 [==============================] - 3s 727us/step - loss: 0.0125 - val_loss: 0.0135\n",
      "Epoch 232/1000\n",
      "3547/3547 [==============================] - 2s 628us/step - loss: 0.0125 - val_loss: 0.0134\n",
      "Epoch 233/1000\n",
      "3547/3547 [==============================] - 2s 550us/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 234/1000\n",
      "3547/3547 [==============================] - 2s 589us/step - loss: 0.0121 - val_loss: 0.0125\n",
      "Epoch 235/1000\n",
      "3547/3547 [==============================] - 2s 583us/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 236/1000\n",
      "3547/3547 [==============================] - 2s 555us/step - loss: 0.0114 - val_loss: 0.0127\n",
      "Epoch 237/1000\n",
      "3547/3547 [==============================] - 2s 537us/step - loss: 0.0110 - val_loss: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 238/1000\n",
      "3547/3547 [==============================] - 2s 605us/step - loss: 0.0118 - val_loss: 0.0126\n",
      "Epoch 239/1000\n",
      "3547/3547 [==============================] - 2s 565us/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 240/1000\n",
      "3547/3547 [==============================] - 2s 566us/step - loss: 0.0113 - val_loss: 0.0131\n",
      "Epoch 241/1000\n",
      "3547/3547 [==============================] - 2s 582us/step - loss: 0.0120 - val_loss: 0.0122\n",
      "Epoch 242/1000\n",
      "3547/3547 [==============================] - 2s 560us/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 243/1000\n",
      "3547/3547 [==============================] - 2s 563us/step - loss: 0.0122 - val_loss: 0.0163\n",
      "Epoch 244/1000\n",
      "3547/3547 [==============================] - 2s 562us/step - loss: 0.0117 - val_loss: 0.0133\n",
      "Epoch 245/1000\n",
      "3547/3547 [==============================] - 2s 568us/step - loss: 0.0120 - val_loss: 0.0183\n",
      "Epoch 246/1000\n",
      "3547/3547 [==============================] - 2s 559us/step - loss: 0.0124 - val_loss: 0.0128\n",
      "Epoch 247/1000\n",
      "3547/3547 [==============================] - 2s 536us/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00247: early stopping\n",
      "(418, 7)\n",
      "(418, 7)\n",
      "(3939, 16, 1)\n",
      "(3939, 10)\n",
      "Train on 3545 samples, validate on 394 samples\n",
      "Epoch 1/1000\n",
      "3545/3545 [==============================] - 2s 642us/step - loss: 4.5559 - val_loss: 0.1806\n",
      "Epoch 2/1000\n",
      "3545/3545 [==============================] - 2s 678us/step - loss: 0.2790 - val_loss: 0.0495\n",
      "Epoch 3/1000\n",
      "3545/3545 [==============================] - 2s 555us/step - loss: 0.1187 - val_loss: 0.0509\n",
      "Epoch 4/1000\n",
      "3545/3545 [==============================] - 2s 548us/step - loss: 0.0820 - val_loss: 0.0347\n",
      "Epoch 5/1000\n",
      "3545/3545 [==============================] - 2s 586us/step - loss: 0.0640 - val_loss: 0.0332\n",
      "Epoch 6/1000\n",
      "3545/3545 [==============================] - 2s 569us/step - loss: 0.0522 - val_loss: 0.0324\n",
      "Epoch 7/1000\n",
      "3545/3545 [==============================] - 2s 574us/step - loss: 0.0462 - val_loss: 0.0262\n",
      "Epoch 8/1000\n",
      "3545/3545 [==============================] - 2s 578us/step - loss: 0.0423 - val_loss: 0.0245\n",
      "Epoch 9/1000\n",
      "3545/3545 [==============================] - 2s 636us/step - loss: 0.0386 - val_loss: 0.0302\n",
      "Epoch 10/1000\n",
      "3545/3545 [==============================] - 2s 462us/step - loss: 0.0360 - val_loss: 0.0237\n",
      "Epoch 11/1000\n",
      "3545/3545 [==============================] - 2s 557us/step - loss: 0.0348 - val_loss: 0.0298\n",
      "Epoch 12/1000\n",
      "3545/3545 [==============================] - 3s 716us/step - loss: 0.0329 - val_loss: 0.0220\n",
      "Epoch 13/1000\n",
      "3545/3545 [==============================] - 2s 677us/step - loss: 0.0323 - val_loss: 0.0256\n",
      "Epoch 14/1000\n",
      "3545/3545 [==============================] - 2s 584us/step - loss: 0.0314 - val_loss: 0.0252\n",
      "Epoch 15/1000\n",
      "3545/3545 [==============================] - 2s 539us/step - loss: 0.0308 - val_loss: 0.0273\n",
      "Epoch 16/1000\n",
      "3545/3545 [==============================] - 2s 533us/step - loss: 0.0290 - val_loss: 0.0259\n",
      "Epoch 17/1000\n",
      "3545/3545 [==============================] - 2s 561us/step - loss: 0.0281 - val_loss: 0.0211\n",
      "Epoch 18/1000\n",
      "3545/3545 [==============================] - 2s 570us/step - loss: 0.0281 - val_loss: 0.0235\n",
      "Epoch 19/1000\n",
      "3545/3545 [==============================] - 2s 561us/step - loss: 0.0287 - val_loss: 0.0304\n",
      "Epoch 20/1000\n",
      "3545/3545 [==============================] - 2s 538us/step - loss: 0.0293 - val_loss: 0.0257\n",
      "Epoch 21/1000\n",
      "3545/3545 [==============================] - 2s 526us/step - loss: 0.0270 - val_loss: 0.0339\n",
      "Epoch 22/1000\n",
      "3545/3545 [==============================] - 2s 599us/step - loss: 0.0260 - val_loss: 0.0270\n",
      "Epoch 23/1000\n",
      "3545/3545 [==============================] - 3s 744us/step - loss: 0.0251 - val_loss: 0.0215\n",
      "Epoch 24/1000\n",
      "3545/3545 [==============================] - 3s 729us/step - loss: 0.0270 - val_loss: 0.0382\n",
      "Epoch 25/1000\n",
      "3545/3545 [==============================] - 3s 720us/step - loss: 0.0271 - val_loss: 0.0320\n",
      "Epoch 26/1000\n",
      "3545/3545 [==============================] - 3s 747us/step - loss: 0.0262 - val_loss: 0.0288\n",
      "Epoch 27/1000\n",
      "3545/3545 [==============================] - 3s 825us/step - loss: 0.0258 - val_loss: 0.0414\n",
      "Epoch 28/1000\n",
      "3545/3545 [==============================] - 3s 714us/step - loss: 0.0259 - val_loss: 0.0375\n",
      "Epoch 29/1000\n",
      "3545/3545 [==============================] - 2s 696us/step - loss: 0.0264 - val_loss: 0.0385\n",
      "Epoch 30/1000\n",
      "3545/3545 [==============================] - 2s 691us/step - loss: 0.0264 - val_loss: 0.0452\n",
      "Epoch 31/1000\n",
      "3545/3545 [==============================] - 2s 691us/step - loss: 0.0264 - val_loss: 0.0576\n",
      "Epoch 32/1000\n",
      "3545/3545 [==============================] - 2s 690us/step - loss: 0.0258 - val_loss: 0.0513\n",
      "Epoch 33/1000\n",
      "3545/3545 [==============================] - 3s 822us/step - loss: 0.0268 - val_loss: 0.0546\n",
      "Epoch 34/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0264 - val_loss: 0.0379\n",
      "Epoch 35/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0278 - val_loss: 0.0608\n",
      "Epoch 36/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0273 - val_loss: 0.0339\n",
      "Epoch 37/1000\n",
      "3545/3545 [==============================] - 3s 741us/step - loss: 0.0261 - val_loss: 0.0700\n",
      "Epoch 38/1000\n",
      "3545/3545 [==============================] - 3s 741us/step - loss: 0.0261 - val_loss: 0.0556\n",
      "Epoch 39/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0257 - val_loss: 0.0570\n",
      "Epoch 40/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0271 - val_loss: 0.0534\n",
      "Epoch 41/1000\n",
      "3545/3545 [==============================] - 3s 733us/step - loss: 0.0254 - val_loss: 0.0454\n",
      "Epoch 42/1000\n",
      "3545/3545 [==============================] - 3s 743us/step - loss: 0.0266 - val_loss: 0.0432\n",
      "Epoch 43/1000\n",
      "3545/3545 [==============================] - 3s 737us/step - loss: 0.0244 - val_loss: 0.0520\n",
      "Epoch 44/1000\n",
      "3545/3545 [==============================] - 3s 736us/step - loss: 0.0267 - val_loss: 0.0756\n",
      "Epoch 45/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0254 - val_loss: 0.0386\n",
      "Epoch 46/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0274 - val_loss: 0.0458\n",
      "Epoch 47/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0245 - val_loss: 0.0573\n",
      "Epoch 48/1000\n",
      "3545/3545 [==============================] - 3s 732us/step - loss: 0.0261 - val_loss: 0.0378\n",
      "Epoch 49/1000\n",
      "3545/3545 [==============================] - 3s 737us/step - loss: 0.0252 - val_loss: 0.0600\n",
      "Epoch 50/1000\n",
      "3545/3545 [==============================] - 3s 756us/step - loss: 0.0247 - val_loss: 0.0260\n",
      "Epoch 51/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0255 - val_loss: 0.0738\n",
      "Epoch 52/1000\n",
      "3545/3545 [==============================] - 3s 771us/step - loss: 0.0232 - val_loss: 0.0756\n",
      "Epoch 53/1000\n",
      "3545/3545 [==============================] - 3s 758us/step - loss: 0.0252 - val_loss: 0.0710\n",
      "Epoch 54/1000\n",
      "3545/3545 [==============================] - 3s 754us/step - loss: 0.0238 - val_loss: 0.0344\n",
      "Epoch 55/1000\n",
      "3545/3545 [==============================] - 3s 731us/step - loss: 0.0247 - val_loss: 0.0507\n",
      "Epoch 56/1000\n",
      "3545/3545 [==============================] - 3s 769us/step - loss: 0.0226 - val_loss: 0.0586\n",
      "Epoch 57/1000\n",
      "3545/3545 [==============================] - 3s 741us/step - loss: 0.0234 - val_loss: 0.0489\n",
      "Epoch 58/1000\n",
      "3545/3545 [==============================] - 3s 724us/step - loss: 0.0244 - val_loss: 0.0259\n",
      "Epoch 59/1000\n",
      "3545/3545 [==============================] - 3s 725us/step - loss: 0.0227 - val_loss: 0.0339\n",
      "Epoch 60/1000\n",
      "3545/3545 [==============================] - 3s 737us/step - loss: 0.0231 - val_loss: 0.0310\n",
      "Epoch 61/1000\n",
      "3545/3545 [==============================] - 3s 752us/step - loss: 0.0237 - val_loss: 0.0463\n",
      "Epoch 62/1000\n",
      "3545/3545 [==============================] - 3s 772us/step - loss: 0.0224 - val_loss: 0.0341\n",
      "Epoch 63/1000\n",
      "3545/3545 [==============================] - 3s 735us/step - loss: 0.0235 - val_loss: 0.0323\n",
      "Epoch 64/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0226 - val_loss: 0.0267\n",
      "Epoch 65/1000\n",
      "3545/3545 [==============================] - 3s 737us/step - loss: 0.0235 - val_loss: 0.0326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0219 - val_loss: 0.0279\n",
      "Epoch 67/1000\n",
      "3545/3545 [==============================] - 3s 743us/step - loss: 0.0221 - val_loss: 0.0488\n",
      "Epoch 68/1000\n",
      "3545/3545 [==============================] - 3s 733us/step - loss: 0.0221 - val_loss: 0.0383\n",
      "Epoch 69/1000\n",
      "3545/3545 [==============================] - 3s 738us/step - loss: 0.0216 - val_loss: 0.0328\n",
      "Epoch 70/1000\n",
      "3545/3545 [==============================] - 3s 732us/step - loss: 0.0202 - val_loss: 0.0237\n",
      "Epoch 71/1000\n",
      "3545/3545 [==============================] - 3s 736us/step - loss: 0.0215 - val_loss: 0.0165\n",
      "Epoch 72/1000\n",
      "3545/3545 [==============================] - 3s 738us/step - loss: 0.0223 - val_loss: 0.0471\n",
      "Epoch 73/1000\n",
      "3545/3545 [==============================] - 3s 735us/step - loss: 0.0220 - val_loss: 0.0386\n",
      "Epoch 74/1000\n",
      "3545/3545 [==============================] - 3s 736us/step - loss: 0.0201 - val_loss: 0.0234\n",
      "Epoch 75/1000\n",
      "3545/3545 [==============================] - 3s 747us/step - loss: 0.0225 - val_loss: 0.0302\n",
      "Epoch 76/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0212 - val_loss: 0.0846\n",
      "Epoch 77/1000\n",
      "3545/3545 [==============================] - 3s 747us/step - loss: 0.0199 - val_loss: 0.0274\n",
      "Epoch 78/1000\n",
      "3545/3545 [==============================] - 3s 747us/step - loss: 0.0203 - val_loss: 0.0390\n",
      "Epoch 79/1000\n",
      "3545/3545 [==============================] - 3s 737us/step - loss: 0.0207 - val_loss: 0.0244\n",
      "Epoch 80/1000\n",
      "3545/3545 [==============================] - 3s 738us/step - loss: 0.0193 - val_loss: 0.0200\n",
      "Epoch 81/1000\n",
      "3545/3545 [==============================] - 3s 737us/step - loss: 0.0203 - val_loss: 0.0188\n",
      "Epoch 82/1000\n",
      "3545/3545 [==============================] - 3s 735us/step - loss: 0.0203 - val_loss: 0.0167\n",
      "Epoch 83/1000\n",
      "3545/3545 [==============================] - 3s 744us/step - loss: 0.0215 - val_loss: 0.0207\n",
      "Epoch 84/1000\n",
      "3545/3545 [==============================] - 3s 745us/step - loss: 0.0221 - val_loss: 0.0463\n",
      "Epoch 85/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0193 - val_loss: 0.0196\n",
      "Epoch 86/1000\n",
      "3545/3545 [==============================] - 3s 731us/step - loss: 0.0185 - val_loss: 0.0197\n",
      "Epoch 87/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0187 - val_loss: 0.0186\n",
      "Epoch 88/1000\n",
      "3545/3545 [==============================] - 3s 738us/step - loss: 0.0185 - val_loss: 0.0165\n",
      "Epoch 89/1000\n",
      "3545/3545 [==============================] - 3s 734us/step - loss: 0.0207 - val_loss: 0.0188\n",
      "Epoch 90/1000\n",
      "3545/3545 [==============================] - 3s 735us/step - loss: 0.0200 - val_loss: 0.0183\n",
      "Epoch 91/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0185 - val_loss: 0.0170\n",
      "Epoch 92/1000\n",
      "3545/3545 [==============================] - 3s 785us/step - loss: 0.0179 - val_loss: 0.0200\n",
      "Epoch 93/1000\n",
      "3545/3545 [==============================] - 3s 762us/step - loss: 0.0191 - val_loss: 0.0175\n",
      "Epoch 94/1000\n",
      "3545/3545 [==============================] - 3s 731us/step - loss: 0.0204 - val_loss: 0.0363\n",
      "Epoch 95/1000\n",
      "3545/3545 [==============================] - 3s 801us/step - loss: 0.0189 - val_loss: 0.0191\n",
      "Epoch 96/1000\n",
      "3545/3545 [==============================] - 3s 751us/step - loss: 0.0189 - val_loss: 0.0181\n",
      "Epoch 97/1000\n",
      "3545/3545 [==============================] - 3s 780us/step - loss: 0.0184 - val_loss: 0.0175\n",
      "Epoch 98/1000\n",
      "3545/3545 [==============================] - 3s 784us/step - loss: 0.0182 - val_loss: 0.0176\n",
      "Epoch 99/1000\n",
      "3545/3545 [==============================] - 3s 758us/step - loss: 0.0190 - val_loss: 0.0175\n",
      "Epoch 100/1000\n",
      "3545/3545 [==============================] - 3s 747us/step - loss: 0.0196 - val_loss: 0.0262\n",
      "Epoch 101/1000\n",
      "3545/3545 [==============================] - 3s 763us/step - loss: 0.0169 - val_loss: 0.0207\n",
      "Epoch 102/1000\n",
      "3545/3545 [==============================] - 3s 775us/step - loss: 0.0183 - val_loss: 0.0185\n",
      "Epoch 103/1000\n",
      "3545/3545 [==============================] - 2s 696us/step - loss: 0.0184 - val_loss: 0.0178\n",
      "Epoch 104/1000\n",
      "3545/3545 [==============================] - 2s 703us/step - loss: 0.0186 - val_loss: 0.0236\n",
      "Epoch 105/1000\n",
      "3545/3545 [==============================] - 2s 693us/step - loss: 0.0172 - val_loss: 0.0174\n",
      "Epoch 106/1000\n",
      "3545/3545 [==============================] - 2s 690us/step - loss: 0.0197 - val_loss: 0.0486\n",
      "Epoch 107/1000\n",
      "3545/3545 [==============================] - 2s 692us/step - loss: 0.0209 - val_loss: 0.0378\n",
      "Epoch 108/1000\n",
      "3545/3545 [==============================] - 3s 772us/step - loss: 0.0186 - val_loss: 0.0166\n",
      "Epoch 109/1000\n",
      "3545/3545 [==============================] - 4s 1ms/step - loss: 0.0193 - val_loss: 0.0179\n",
      "Epoch 110/1000\n",
      "3545/3545 [==============================] - 3s 917us/step - loss: 0.0186 - val_loss: 0.0197\n",
      "Epoch 111/1000\n",
      "3545/3545 [==============================] - 3s 749us/step - loss: 0.0189 - val_loss: 0.0204\n",
      "Epoch 112/1000\n",
      "3545/3545 [==============================] - 3s 756us/step - loss: 0.0183 - val_loss: 0.0171\n",
      "Epoch 113/1000\n",
      "3545/3545 [==============================] - 3s 738us/step - loss: 0.0170 - val_loss: 0.0175\n",
      "Epoch 114/1000\n",
      "3545/3545 [==============================] - 3s 716us/step - loss: 0.0184 - val_loss: 0.0175\n",
      "Epoch 115/1000\n",
      "3545/3545 [==============================] - 3s 811us/step - loss: 0.0175 - val_loss: 0.0170\n",
      "Epoch 116/1000\n",
      "3545/3545 [==============================] - 3s 854us/step - loss: 0.0190 - val_loss: 0.0314\n",
      "Epoch 117/1000\n",
      "3545/3545 [==============================] - 3s 859us/step - loss: 0.0183 - val_loss: 0.0326\n",
      "Epoch 118/1000\n",
      "3545/3545 [==============================] - 3s 728us/step - loss: 0.0175 - val_loss: 0.0198\n",
      "Epoch 119/1000\n",
      "3545/3545 [==============================] - 3s 717us/step - loss: 0.0185 - val_loss: 0.0248\n",
      "Epoch 120/1000\n",
      "3545/3545 [==============================] - 3s 913us/step - loss: 0.0180 - val_loss: 0.0168\n",
      "Epoch 121/1000\n",
      "3545/3545 [==============================] - 3s 831us/step - loss: 0.0174 - val_loss: 0.0200\n",
      "Epoch 122/1000\n",
      "3545/3545 [==============================] - 3s 981us/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 123/1000\n",
      "3545/3545 [==============================] - 3s 781us/step - loss: 0.0176 - val_loss: 0.0170\n",
      "Epoch 124/1000\n",
      "3545/3545 [==============================] - 2s 702us/step - loss: 0.0184 - val_loss: 0.0253\n",
      "Epoch 125/1000\n",
      "3545/3545 [==============================] - 2s 696us/step - loss: 0.0195 - val_loss: 0.0225\n",
      "Epoch 126/1000\n",
      "3545/3545 [==============================] - 3s 735us/step - loss: 0.0181 - val_loss: 0.0168\n",
      "Epoch 127/1000\n",
      "3545/3545 [==============================] - 3s 757us/step - loss: 0.0185 - val_loss: 0.0186\n",
      "Epoch 128/1000\n",
      "3545/3545 [==============================] - 3s 783us/step - loss: 0.0173 - val_loss: 0.0248\n",
      "Epoch 129/1000\n",
      "3545/3545 [==============================] - 3s 720us/step - loss: 0.0181 - val_loss: 0.0180\n",
      "Epoch 130/1000\n",
      "3545/3545 [==============================] - 3s 917us/step - loss: 0.0179 - val_loss: 0.0173\n",
      "Epoch 131/1000\n",
      "3545/3545 [==============================] - 4s 1ms/step - loss: 0.0193 - val_loss: 0.0337\n",
      "Epoch 132/1000\n",
      "3545/3545 [==============================] - 3s 818us/step - loss: 0.0189 - val_loss: 0.0229\n",
      "Epoch 133/1000\n",
      "3545/3545 [==============================] - 3s 768us/step - loss: 0.0168 - val_loss: 0.0198\n",
      "Epoch 134/1000\n",
      "3545/3545 [==============================] - 3s 708us/step - loss: 0.0171 - val_loss: 0.0174\n",
      "Epoch 135/1000\n",
      "3545/3545 [==============================] - 3s 715us/step - loss: 0.0175 - val_loss: 0.0245\n",
      "Epoch 136/1000\n",
      "3545/3545 [==============================] - 3s 783us/step - loss: 0.0174 - val_loss: 0.0246\n",
      "Epoch 137/1000\n",
      "3545/3545 [==============================] - 3s 716us/step - loss: 0.0171 - val_loss: 0.0219\n",
      "Epoch 138/1000\n",
      "3545/3545 [==============================] - 3s 727us/step - loss: 0.0172 - val_loss: 0.0185\n",
      "Epoch 139/1000\n",
      "3545/3545 [==============================] - 3s 753us/step - loss: 0.0177 - val_loss: 0.0172\n",
      "Epoch 140/1000\n",
      "3545/3545 [==============================] - 3s 765us/step - loss: 0.0171 - val_loss: 0.0338\n",
      "Epoch 141/1000\n",
      "3545/3545 [==============================] - 3s 828us/step - loss: 0.0179 - val_loss: 0.0230\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3545/3545 [==============================] - 3s 973us/step - loss: 0.0175 - val_loss: 0.0179\n",
      "Epoch 143/1000\n",
      "3545/3545 [==============================] - 3s 797us/step - loss: 0.0167 - val_loss: 0.0233\n",
      "Epoch 144/1000\n",
      "3545/3545 [==============================] - 3s 731us/step - loss: 0.0163 - val_loss: 0.0226\n",
      "Epoch 145/1000\n",
      "3545/3545 [==============================] - 3s 725us/step - loss: 0.0170 - val_loss: 0.0208\n",
      "Epoch 146/1000\n",
      "3545/3545 [==============================] - 3s 739us/step - loss: 0.0169 - val_loss: 0.0209\n",
      "Epoch 147/1000\n",
      "3545/3545 [==============================] - 3s 706us/step - loss: 0.0168 - val_loss: 0.0235\n",
      "Epoch 148/1000\n",
      "3545/3545 [==============================] - 3s 705us/step - loss: 0.0170 - val_loss: 0.0177\n",
      "Epoch 149/1000\n",
      "3545/3545 [==============================] - 3s 720us/step - loss: 0.0173 - val_loss: 0.0169\n",
      "Epoch 150/1000\n",
      "3545/3545 [==============================] - 3s 724us/step - loss: 0.0178 - val_loss: 0.0184\n",
      "Epoch 151/1000\n",
      "3545/3545 [==============================] - 3s 790us/step - loss: 0.0177 - val_loss: 0.0181\n",
      "Epoch 152/1000\n",
      "3545/3545 [==============================] - 3s 884us/step - loss: 0.0174 - val_loss: 0.0367\n",
      "Epoch 153/1000\n",
      "3545/3545 [==============================] - 3s 730us/step - loss: 0.0202 - val_loss: 0.0696\n",
      "Epoch 154/1000\n",
      "3545/3545 [==============================] - 3s 755us/step - loss: 0.0181 - val_loss: 0.0178\n",
      "Epoch 155/1000\n",
      "3545/3545 [==============================] - 3s 726us/step - loss: 0.0172 - val_loss: 0.0192\n",
      "Epoch 156/1000\n",
      "3545/3545 [==============================] - 3s 720us/step - loss: 0.0169 - val_loss: 0.0170\n",
      "Epoch 157/1000\n",
      "3545/3545 [==============================] - 3s 750us/step - loss: 0.0174 - val_loss: 0.0207\n",
      "Epoch 158/1000\n",
      "3545/3545 [==============================] - 3s 983us/step - loss: 0.0166 - val_loss: 0.0167\n",
      "Epoch 159/1000\n",
      "3545/3545 [==============================] - 4s 1ms/step - loss: 0.0164 - val_loss: 0.0198\n",
      "Epoch 160/1000\n",
      "3545/3545 [==============================] - 4s 1ms/step - loss: 0.0166 - val_loss: 0.0189\n",
      "Epoch 161/1000\n",
      "3545/3545 [==============================] - 3s 826us/step - loss: 0.0154 - val_loss: 0.0223\n",
      "Epoch 162/1000\n",
      "3545/3545 [==============================] - 3s 770us/step - loss: 0.0163 - val_loss: 0.0221\n",
      "Epoch 163/1000\n",
      "3545/3545 [==============================] - 3s 708us/step - loss: 0.0160 - val_loss: 0.0202\n",
      "Epoch 164/1000\n",
      "3545/3545 [==============================] - 3s 747us/step - loss: 0.0167 - val_loss: 0.0173\n",
      "Epoch 165/1000\n",
      "3545/3545 [==============================] - 3s 827us/step - loss: 0.0160 - val_loss: 0.0174\n",
      "Epoch 166/1000\n",
      "3545/3545 [==============================] - 3s 959us/step - loss: 0.0163 - val_loss: 0.0165\n",
      "Epoch 167/1000\n",
      "3545/3545 [==============================] - 4s 1ms/step - loss: 0.0170 - val_loss: 0.0188\n",
      "Epoch 168/1000\n",
      "3545/3545 [==============================] - 4s 1ms/step - loss: 0.0167 - val_loss: 0.0188\n",
      "Epoch 169/1000\n",
      "3545/3545 [==============================] - 3s 906us/step - loss: 0.0174 - val_loss: 0.0297\n",
      "Epoch 170/1000\n",
      "3545/3545 [==============================] - 3s 737us/step - loss: 0.0161 - val_loss: 0.0236\n",
      "Epoch 171/1000\n",
      "3545/3545 [==============================] - 3s 762us/step - loss: 0.0162 - val_loss: 0.0174\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00171: early stopping\n",
      "(415, 10)\n",
      "(415, 10)\n"
     ]
    }
   ],
   "source": [
    "for step in output_time_step:\n",
    "    \n",
    "    # Creating supervised dataset\n",
    "    in_start = 0\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for i in range(len(df_train_scale)):\n",
    "        in_end = in_start + input_time_step\n",
    "        out_end = in_end + step\n",
    "        if out_end < len(df_train_scale):\n",
    "            x_train.append(df_train_scale[in_start:in_end, 0])\n",
    "            y_train.append(df_train_scale[in_end:out_end, 0])\n",
    "        in_start += 1\n",
    "    x_train, y_train = np.array(x_train), np.array(y_train)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "    \n",
    "    # TCN Model\n",
    "    i = Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
    "    m = TCN(nb_filters=units, dilations=dilations, dropout_rate=dropout)(i)\n",
    "    m = Dense(step, activation='linear')(m)\n",
    "    model = Model(inputs=[i], outputs=[m])\n",
    "\n",
    "    model.compile(optimizer = optimizer, loss = loss)\n",
    "    \n",
    "    # Training Model\n",
    "    history = model.fit(x_train, \n",
    "                        y_train,\n",
    "                        validation_split = validation_split,\n",
    "                        callbacks = [callback], \n",
    "                        epochs = epoch, \n",
    "                        batch_size = batch_size, \n",
    "                        shuffle = False)\n",
    "    \n",
    "    \n",
    "    # Prediction on Test Set\n",
    "    pred_vector = np.empty((0, step))\n",
    "    real_vector = np.empty((0, step))\n",
    "\n",
    "    for i in range(df_test_scale.size):\n",
    "\n",
    "        if(i+step+input_time_step < df_test_scale.size): \n",
    "            val = df_test_scale[i:i+input_time_step]\n",
    "            #print(i, i+input_time_step)\n",
    "            val = val.reshape((1, len(val), 1))\n",
    "            #print(val.shape)\n",
    "            pred = model.predict(val)\n",
    "            pred = sc.inverse_transform(pred)\n",
    "            pred_vector = np.append(pred_vector,pred,axis=0)\n",
    "            real = df_test_scale[i+input_time_step:i+input_time_step+step].reshape(1,step)\n",
    "            #print(i+input_time_step,i+input_time_step+output_time_step)\n",
    "            real = sc.inverse_transform(real)\n",
    "            real_vector = np.append(real_vector,real,axis=0)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(pred_vector.shape)\n",
    "    print(real_vector.shape)\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    sum_mae = 0\n",
    "    sum_rmse = 0\n",
    "    for i in range(len(pred_vector)):#same as real_vector\n",
    "        mae = metrics.mean_absolute_error(real_vector[i], pred_vector[i])\n",
    "        mse = metrics.mean_squared_error(real_vector[i], pred_vector[i])\n",
    "        rmse = np.sqrt(mse)\n",
    "        sum_mae = sum_mae + mae\n",
    "        sum_rmse = sum_rmse + rmse\n",
    "\n",
    "    # Average MAE\n",
    "    avg_mae = sum_mae / len(pred_vector)\n",
    "    # Average RMSE\n",
    "    avg_rmse = sum_rmse / len(pred_vector)\n",
    "    \n",
    "    RMSE.append(avg_rmse)\n",
    "    MAE.append(avg_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0037925387647696034,\n",
       " 0.004459273720139456,\n",
       " 0.005376743832355205,\n",
       " 0.00620982559372576,\n",
       " 0.007730568012738312]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f92146ba510>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output_time_step,RMSE, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.003519443386812868,\n",
       " 0.0040041392693964065,\n",
       " 0.0047168383909770425,\n",
       " 0.005428164752867644,\n",
       " 0.006765662151116054]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9215432cd0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(output_time_step,RMSE, marker='o')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
